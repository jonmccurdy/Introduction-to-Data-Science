[
  {
    "objectID": "Lecture-1-What-is-Data.html",
    "href": "Lecture-1-What-is-Data.html",
    "title": "1  What is Data?",
    "section": "",
    "text": "1.1 Data-fication\nAs we begin our journey to becoming Data Scientists, it is important to get a firm grasp of what data actually is. There are many ways to define data. If you were to look at the origin of the word, you would see that it is the plural of the Latin word “datum”, which means piece of information. You might propose other definitions, such as: Information collected about something, or Facts and Statistics used to calculate something. All of these are acceptable interpretations of data, and we will probably switch between them throughout the semester. But, it is important to acknowledge that data (the individual pieces of information) by itself is essentially meaningless, it is through interpretation that it gains meaning. And that is what we will learn throughout this semester; how to interpret pieces of information to tell a story.\nTechnology has become an integral part of our daily life. Almost everything we do tracks and collects data on us. This includes checking our social media in the morning, purchasing food with our credit card, and even “scanning” our ID to enter buildings. Every company we interact with collects data on us whether we like it or not, including the Government. It should be mentioned that not all of this is bad. The school collects information about what classes you have passed, credit card companies collect information to determine how reliable you are in paying your bills, and hospitals collect medical history about you to improve your level of care.\nBecause of the large amount of data that is floating around in the “wild”, scientists say that we are currently in the “Age of Information/Data”. Another term, coined in a 2013 article titled “The Rise of Big Data”, describes the process of “taking all aspects of life and turning them into data [\\(\\dots\\)] Once we datafy things, we can transform their purpose and turn the information into new forms of value.” This results in a “digital footprint”; as we leave a trail of data about ourselves wherever we go. This digit footprint starts when we are born and follows us throughout our lives. Companies are able to change/tweak products based on the data they collect about our preferences (think how social media evolved based on the apps we used), but these products can also change how we behave (think social media addiction).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Data?</span>"
    ]
  },
  {
    "objectID": "Lecture-1-What-is-Data.html#communicating-with-data",
    "href": "Lecture-1-What-is-Data.html#communicating-with-data",
    "title": "1  What is Data?",
    "section": "1.2 Communicating with Data",
    "text": "1.2 Communicating with Data\nSo all of this data is available, but why should we care exactly? Well, all of this data allows us to do some pretty cool things. In the previous section, we mentioned how credit card companies can determine if we are dependable. They do this by taking our past payment history and other information about us, such as age, gender, and income level, and then building a model to decide if we will end up paying off the loan or defaulting on it. Other scenarios might be to predict the outcomes of NFL games, analyze weather patterns to better understand hurricane trajectory, or even recommend movies on Netflix/products on Amazon. All of these things are done with data, and when we build these models we are doing Data Science. There are many definitions out there for Data Science, but one of the ones I like is the following: Data Science unlocks hidden stories within vast amounts of data, paving the way for innovations that transform industries and improve lives.\nSince Data Science involves the process of unlocking and telling stories, it is important for us to ask ourselves what exactly makes a good story. In middle school and high school, I am sure we were taught that every story should have a beginning (the Introduction), a middle (the “Plot”), and an ending (the Conclusion). As Data Scientists, we will need to communicate our results in a similar way (as a data story) in order for people to understand our findings. So, we should also start to think about how we convey a data story so other people can understand it. If we are predicting the miles per gallon a car will have, then we will present our story differently to kindergartners than we would to automotive experts. So, it is important to write our story with our audience in mind. To help the presentation, we will want to incorporate visualizations to engage the audience and support our plot.\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit and his friends have been complaining that the campus dining hall lines are way too long during lunch. Emmit decides to track how long he waits each day for a week, and also asks his friends to do the same. He collects data on wait times, day of the week, and time of day. How can Emmit turn this data into a compelling story? Who is his audience, and what would be a good way to visualize his findings?\n\n\nClick to see the solution",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Data?</span>"
    ]
  },
  {
    "objectID": "Lecture-1-What-is-Data.html#classifying-data",
    "href": "Lecture-1-What-is-Data.html#classifying-data",
    "title": "1  What is Data?",
    "section": "1.3 Classifying Data",
    "text": "1.3 Classifying Data\nThere are a number of ways to classify the data that we will encounter throughout this course. The first big division will be deciding whether the data is Quantitative or Qualitative. Quantitative data are anything that is a count or a measure (think quantities) while Qualitative data are things that cannot be expressed using numbers (think categories). Depending on what type of data we have will determine how we analyze and visualize it.\nQuantitative data can be broken up into two more categories. We will say the data is Continuous if it can take on infinitely many values in a given interval. What this essentially means is that if it makes sense to add additional decimal places then it is probably continuous data. Examples of this include temperature (it makes sense for something to be 74.3\\(^\\circ\\) F or even 74.3138\\(^\\circ\\) F if our measurement device is precise enough), weight, and time. We need to be careful, as continuous data does not mean that it is continuously changing, it means that it can take any value in an interval.\n\n\n\n\n\n\nWarning\n\n\n\nJust because a value has decimals doesn’t mean it’s continuous! Think about whether additional precision makes sense.\n\n\nThe other type of quantitative data will be Discrete data. If our data can only take on certain values in a given interval then it will be Discrete data. This includes the number of people at a party (it has to be a whole number as we can’t have a fraction of a person), a person’s shoe size, and the amount of money they have in their wallet. Notice that some of these may have decimal places, like shoe size, but still be considered discrete data since it does not make sense to have an additional decimal place. One mistake students often make is saying that there is a finite number of possibilities for discrete data. This is false, there can be an infinite number of values (theoretically there be \\(0, 1, 2, 3, \\cdots\\) all the way to infinity number of people in a room, but it has to be a whole number) as long as the data can only take on certain values in the interval.\nQualitative (categorical) data can also be broken up into two groups. These groups depend on whether the data can be ordered or not. Nominal data has no implied ordering. Examples of this might be gender, color, or fruits as it does not make sense to say that one ordering is correct (it doesn’t make sense to say male comes before female or vice versa). Ordinal data can be ordered. This might include grade classification (Freshman, Sophomore, Junior, Senior), letter grades, and drink sizes (small, medium, and large). All of these make sense to put in a specific order.\nThroughout the course, before we start analyzing data it is important to stop and think about what type of data we have. You will need to differentiate whether it us Qualitative or Quantitative. If it is Quantitative then is it Continuous or Discrete. If it is Qualitative then is it Nominal or Ordinal. For instance, we might say that it is Quantitative Continuous or Qualitative Nominal. We will never mix the classifications, for instance, we will never have Qualitative Discrete or Quantitative Ordinal Continuous, as this does not make sense. There are many additional ways we could classify our data, but we will just stick with these basic classifications for now.\n\n\n\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit is organizing a spreadsheet of his week to track habits and mood. Help classify each of Emmit’s variables as Quantitative Continuous, Quantitative Discrete, Qualitative Nominal, or Qualitative Ordinal:\n\nSleep hours\nNumber of texts sent\nMood (happy, okay, sad)\nYear in college\n\n\n\nClick to see the solution\n\n\n\n\n\n\n\n\nExplain why raw data alone is not meaningful without interpretation.\nGive an example of a decision or prediction you’ve seen (in apps, services, or media) that likely used data. What data was probably used?\nWhy is it important to consider your audience when presenting data? Give one example of how you’d present the same data differently to two groups.\nFor each variable, classify it as one of the following: Quantitative Continuous, Quantitative Discrete, Qualitative Nominal, Qualitative Ordinal\n\nHeight in inches\n\nShirt size (S, M, L, XL)\n\nNumber of steps walked\n\nRating of a movie (1 to 5 stars)\n\nWhy would “Quantitative Ordinal Continuous” be an invalid classification?\nThink of one variable from your daily life. Write down the variable and explain how you would classify it and why.\nWrite a short “data story” (4–5 sentences) using any 3 variables of your choice. Specify your audience and how you’d visualize it.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Data?</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Data Science with R",
    "section": "",
    "text": "Welcome\nWelcome to an Introduction to Data Science!\nThis online book is designed to guide you step by step as you build both the technical skills and the critical thinking needed to work with data. Along the way, you’ll learn how to ask good questions, organize and analyze information in R, and communicate your findings clearly to others.\nThe chapters are filled with examples, practice problems, and short stories about Emmit — a character you’ll get to know as you apply your skills in fun and practical ways. Each section is scaffolded to help you practice, reflect, and gain confidence as you progress. Additionally, there are downloadable reading guides and activities to assist you in your learning journey.\nWhether you’re brand new to programming, statistics, or data science, or you’ve had some experience before, this book is meant to meet you where you are and help you grow. By the end, you’ll not only understand the concepts but also feel confident using them in real-world situations.\n\nNote\nThis textbook was written by Dr. Jon McCurdy for Mount St. Mary’s University’s Introduction to Data Science course. Special Thanks to student Luke Papayoanou for his input along with developing the MSMU package in R to go along with this book.\n\n\n\n\n Dr. Jon McCurdy\n\n\n Luke Papayoanou",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#watch-this-video",
    "href": "index.html#watch-this-video",
    "title": "Introduction to Data Science with R",
    "section": "Watch this video",
    "text": "Watch this video\nWe can add a video fairly easily with the following code (modestbranding reduces logo and rel=0 does not suggest other channels when paused)\n(https://quarto.org/docs/authoring/videos.html)",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#callout-boxes",
    "href": "index.html#callout-boxes",
    "title": "Introduction to Data Science with R",
    "section": "Callout Boxes",
    "text": "Callout Boxes\nWe can make callout boxes for note, warning, important, tip, and caution\n(https://quarto.org/docs/authoring/callouts.html)\n\n\n\n\n\n\nNote\n\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\nTip with Title\n\n\n\nThis is an example of a callout with a title.\n\n\n\n\n\n\n\n\nExpand To Learn About Collapse\n\n\n\n\n\nThis is an example of a ‘folded’ caution callout that can be expanded by the user. You can use collapse=\"true\" to collapse it by default or collapse=\"false\" to make a collapsible callout that is expanded by default.\n\n\n\n\n\n\n\n\n\nTip with Title\n\n\n\nThis is a callout with a title.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#sample-questions-for-students",
    "href": "index.html#sample-questions-for-students",
    "title": "Introduction to Data Science with R",
    "section": "Sample Questions for Students",
    "text": "Sample Questions for Students\n\n\n\n\n\n\nTry it Out\n\n\n\nWhat is the output of mean(c(1, 2, 3, 4, 5)) in R?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe output is 3. This is because it calculates the arithmetic mean:\n(1 + 2 + 3 + 4 + 5) / 5 = 15 / 5 = 3.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#creating-problems-for-students-to-try",
    "href": "index.html#creating-problems-for-students-to-try",
    "title": "Introduction to Data Science with R",
    "section": "Creating Problems for Students to Try",
    "text": "Creating Problems for Students to Try\n\n\n\n\n\n\nTry it Out\n\n\n\nWhat is the output of mean(c(1, 2, 3, 4, 5)) in R?\n\n\nClick to see the solution\n\nThe output is 3. This is because it calculates the arithmetic mean:\n(1 + 2 + 3 + 4 + 5) / 5 = 15 / 5 = 3.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#creating-quiz-questions-for-students",
    "href": "index.html#creating-quiz-questions-for-students",
    "title": "Introduction to Data Science with R",
    "section": "Creating Quiz Questions for Students",
    "text": "Creating Quiz Questions for Students\n(https://web.mat.upc.edu/joaquim.puig/posts/webexercises-quiz/)\n\nNumeric questions How much is 2+3? \nMultiple Choice Which is the capital city of Barbados? BridgetownGeorgetownKingstonBridgerton\nTrue or False Quarto is very cool TRUEFALSE.\nFill in the Blank What is the letter after D? .\nType a vowel: \nWhich function will help me find standard deviation for the code: (c(1,4,7,8,4))\n\nTesting 123",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "Lecture-1-What-is-Data.html#excerices",
    "href": "Lecture-1-What-is-Data.html#excerices",
    "title": "1  What is Data?",
    "section": "1.4 Excerices",
    "text": "1.4 Excerices\n\nNumeric questions How much is 2+3? r fitb(2+3)\nMultiple Choice Which is the capital city of Barbados? r mcq(c(answer=\"Bridgetown\", \"Georgetown\",             \"Kingston\", \"Bridgerton\"))\nTrue or False Quarto is very cool r torf(TRUE).\nFill in the Blank What is the letter after D? r fitb(\"E\", ignore_case = TRUE).\nType a vowel: r fitb(c(\"A\", \"E\", \"I\", \"O\" , \"U\"), ignore_case = TRUE)\nWhich function will help me find standard deviation for the code: r fitb(\"sd\")(c(1,4,7,8,4))\nHow many categories are used to classify qualitative and quantitative data in this course? r fitb(4)\nWhich of the following is Quantitative Continuous data? r mcq(c(\"Number of pets owned\", \"T-shirt size\", answer=\"Amount of rainfall in inches\", \"Favorite movie genre\"))\nThe data type for “Student ID number” is Qualitative Nominal. r torf(TRUE)\nIf a variable can only take whole number values (like goals scored in a soccer match), it is classified as r fitb(\"Discrete\", ignore_case = TRUE) data.\nWhich of the following could reasonably be classified as Ordinal data? r checkbox(c(answer=\"Military ranks\", answer=\"Survey responses (Strongly disagree to Strongly agree)\", \"Blood type\", \"Zip code\"))\nMatch the data types to the best examples:\nr match_list(   list(     \"Quantitative Continuous\" = \"Speed of a race car in mph\",     \"Quantitative Discrete\" = \"Number of people in line\",     \"Qualitative Nominal\" = \"Favorite board game\",     \"Qualitative Ordinal\" = \"Job satisfaction rating (Low, Medium, High)\"   ) )\n\n\n\nExplain why raw data alone is not meaningful without interpretation.\nGive an example of a decision or prediction you’ve seen (in apps, services, or media) that likely used data. What data was probably used?\nWhy is it important to consider your audience when presenting data? Give one example of how you’d present the same data differently to two groups.\nFor each variable, classify it as one of the following: Quantitative Continuous, Quantitative Discrete, Qualitative Nominal, Qualitative Ordinal\n\nNumber of text messages sent yesterday\nFavorite type of cuisine\nHigh school graduation year\nDrink sizes (Small, Medium, Large)\n\nWhy would “Quantitative Ordinal Continuous” be an invalid classification?\nThink of one variable from your daily life. Write down the variable and explain how you would classify it and why.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Data?</span>"
    ]
  },
  {
    "objectID": "Lecture-1-What-is-Data.html#creating-quiz-questions-for-students",
    "href": "Lecture-1-What-is-Data.html#creating-quiz-questions-for-students",
    "title": "1  What is Data?",
    "section": "1.4 Creating Quiz Questions for Students",
    "text": "1.4 Creating Quiz Questions for Students\n(https://web.mat.upc.edu/joaquim.puig/posts/webexercises-quiz/)\n\nHow many categories are used to classify qualitative and quantitative data in this course? \nWhich of the following is Quantitative Continuous data? Number of pets ownedT-shirt sizeAmount of rainfall in inchesFavorite movie genre\nThe data type for “Student ID number” is Qualitative Nominal. TRUEFALSE\nIf a variable can only take whole number values (like goals scored in a soccer match), it is classified as  data.\n\n\n\nExplain why raw data alone is not meaningful without interpretation.\nGive an example of a decision or prediction you’ve seen (in apps, services, or media) that likely used data. What data was probably used?\nWhy is it important to consider your audience when presenting data? Give one example of how you’d present the same data differently to two groups.\nFor each variable, classify it as one of the following: Quantitative Continuous, Quantitative Discrete, Qualitative Nominal, Qualitative Ordinal\n\nNumber of text messages sent yesterday\nFavorite type of cuisine\nHigh school graduation year\nDrink sizes (Small, Medium, Large)\n\nWhy would “Quantitative Ordinal Continuous” be an invalid classification?\nThink of one variable from your daily life. Write down the variable and explain how you would classify it and why.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Data?</span>"
    ]
  },
  {
    "objectID": "Lecture-2-Data-Detectives.html",
    "href": "Lecture-2-Data-Detectives.html",
    "title": "2  Data Detectives",
    "section": "",
    "text": "2.1 Describing the Center\nOne of the goals of this class is learning how to describe data and use it to convey information about the variable of interest. To do this, we will need to discuss some basic statistical formulas that we will use throughout the semester. We will need to learn “how to do” the math in this section, but we should also put an emphasis on the meaning of each term and what it is telling us. Later on in this course, we will be able to calculate all of these formulas using computer software, but we will still need to know what the results are telling us.\nIt may seem odd, but there are multiple ways to describe the center of a dataset. Sometimes we might want the center to describe the mathematical mean (the average on a test was 83.5), other times we might want it to describe the middle value (half of the students got above an 86 on the test), and other times we might want to describe it as the value occurring the most often (the most common grade on the test was an 89). All of these are acceptable ways to discuss the center of a dataset, but they still tell us very different things.\nThe first method we will discuss is probably something we are all familiar with, and that is the mean. The mean is the average value of the data set and is calculated by summing up all of the values and dividing by the number of observations. Next, we have the median, which is the middle value in the data set where half of the values are below it and half of the values are above it. To calculate the median we will order the observations from smallest to largest and then choose the middle observation. If there is an even number of observations then a middle value will not be present and you will need to take the mean of the middle two values to calculate the median. Finally, we have the mode. This is the value that occurs most often and is found by choosing the one that has the highest frequency. There may be no mode, one mode, or multiple modes depending on the dataset.\nBelow is an example of how we can calculate the center of the dataset using the three terms above. The data describes the average game attendance for the 13 basketball teams in the Metro Atlantic Athletic Conference for the 2024-2025 competition year.\nCollege\nMean Attendance\n\n\n\n\nCanisius\n847\n\n\nFairfield\n2135\n\n\nIona\n1822\n\n\nManhattan\n769\n\n\nMarist\n2025\n\n\nMerrimack\n1462\n\n\nMount St. Mary’s\n1888\n\n\nNiagara\n855\n\n\nQuinnipiac\n1510\n\n\nRider\n1540\n\n\nSacred Heart\n1209\n\n\nSaint Peter’s\n539\n\n\nSiena\n5044\nWe can notice that both the mean (1665) and the median (1510) tell us very different stories about what the average attendance was at the basketball games. One reason for this is because the mean is impacted by extreme values, which we will call outliers. These are values that are much smaller or larger than the rest of the dataset. For our dataset, it appears that Siena is an outlier since their attendance is much larger than the rest of the conference. If we were to temporarily remove this value from the dataset the mean would drop to roughly 1383 while the median would only change slightly to 1486. Through this, we can see that the mean is heavily influenced by outliers while the median is relatively immune to them (the median changed a good amount in our dataset since we have relatively few observations, if we had 100 different schools then we would not expect the median to be affected by outliers).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Detectives</span>"
    ]
  },
  {
    "objectID": "Lecture-2-Data-Detectives.html#describing-the-center",
    "href": "Lecture-2-Data-Detectives.html#describing-the-center",
    "title": "2  Data Detectives",
    "section": "",
    "text": "Try it Out\n\n\n\nEmmit is trying to evaluate how well-attended the recent campus speaker series was. After looking at the sign-in sheet he found they had the following attendance amounts:\n\\(52,\\ 73,\\ 84,\\ 73,\\ 82,\\ 253,\\ 82,\\ 48,\\ 73,\\ 80\\)\nIf Emmit claims that “around 90 people come to each event,” is that accurate?\n\n\nClick to see the solution",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Detectives</span>"
    ]
  },
  {
    "objectID": "Lecture-2-Data-Detectives.html#describing-the-spread",
    "href": "Lecture-2-Data-Detectives.html#describing-the-spread",
    "title": "2  Data Detectives",
    "section": "2.2 Describing the Spread",
    "text": "2.2 Describing the Spread\nAnother way to describe a dataset is to talk about the spread of the data. Much like the center, this too can be done in several different ways. The first way we can do this is by calculating the range difference (often called the range). This takes the maximum value (5044) and the minimum value (539) and subtracts them from each other. This will give us a range difference (max - min) of 4505, indicating the data is spread out over 4505 values.\nAn alternative way to discuss the spread of data is by calculating the standard deviation. This is a measure that tells us how far apart on average the values are from the mean. This calculation requires a few steps, with the first being to calculate the mean of the data. Second, you will need to calculate how far each value deviates from the mean (that is the value - mean). Third you will need to square all of the deviations, with the fourth step being adding up all of these squared deviations. Finally, you will divide by the number of observations minus 1 and then take the square root. While this sounds complicated, it can be done by making a table. An example of this can be seen below:\n\n\n\n\n\nLooking at the example above, we can see that the data values are on average 1,137.5 away from the mean. Similar to the mean, the standard deviation is also affected by outliers. If we were to temporarily remove the outlier (Siena) then the standard deviation would drop to roughly 535.8 It is important to understand what the standard deviation is telling us and the general method for calculating it, as the topic will come up throughout this semester and your Data Science journey.\nOne of the many reasons why the standard deviation is important is because it allows us to compare datasets that might have different units. For instance, if we have a dataset describing heights and a dataset describing weights then just talking about the range difference or the standard deviation will not give us insight if one dataset is more spread out than the other. What might be beneficial is discussing the standard deviation range difference, as this is a statistical term to calculate how many standard deviations the maximum value differs from the minimum value. In our basketball attendance example, the standard deviation range difference will be \\(\\displaystyle \\frac{4505}{1137.5}=3.96\\). This tells us the data falls over a range of 3.96 standard deviations.\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit is helping the finance office estimate how much students spend weekly on coffee on campus. How can he best describe the spread of the data?\n\\(\\$10,\\ \\$15,\\ \\$13,\\ \\$14,\\ \\$70,\\ \\$13,\\ \\$14,\\ \\$16,\\ \\$13,\\ \\$12\\)\n\n\nClick to see the solution",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Detectives</span>"
    ]
  },
  {
    "objectID": "Lecture-2-Data-Detectives.html#calculating-z-score",
    "href": "Lecture-2-Data-Detectives.html#calculating-z-score",
    "title": "2  Data Detectives",
    "section": "2.3 Calculating z-Score",
    "text": "2.3 Calculating z-Score\nAnother useful technique to compare values is to determine how many standard deviations away from the mean values are. This might help us see if certain values are “extremes”. To do this we will find the standard score (also called the z-score) which is calculated as:\n\\[\n\\text{z-score}=\\frac{\\text{Observed} - \\text{ Mean}}{\\text{Standard Deviation}}\n\\]\nFor our example, Mount St. Mary’s University has a z-score of \\(0.20\\) while a school that has an average attendance of 900 spectators has a z-score of \\(-0.67\\). Stating how far an observation is away from the mean in terms of standard deviations helps give it more meaning.\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit scores an 70 on a chemistry exam while his friend Mary scores an 85. The class average was 75 with a standard deviation of 3.5. What were their \\(z\\)-scores?\n\n\nClick to see the solution\n\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Detectives</span>"
    ]
  },
  {
    "objectID": "Lecture-2-Data-Detectives.html#visualizing-the-data",
    "href": "Lecture-2-Data-Detectives.html#visualizing-the-data",
    "title": "2  Data Detectives",
    "section": "2.4 Visualizing the Data",
    "text": "2.4 Visualizing the Data\nVisualizing data is also an important part of data science. We will discuss many visualization techniques later in the semester, but we do want to discuss a few big ones now. The first will be the histogram, which will help us visualize quantitative data. With this visualization, the height of the bar corresponds to how many observations have values within the interval. We should note that the bars are all touching each other since it is quantitative data. While this visualization will help convey information about the data, it does lose some of its detail due to the length of each category. In our visualization below, colleges that have an average attendance of 1001 and 1999 are lumped into the same category when one is almost double the other.\nAn additional technique that we will make use of throughout the semester is the density plot, which can be thought of as a smoothing curve for the histogram. It is more detailed than the histogram since it can highlight certain spots where more or less data lie and it alleviates some of the issues mentioned with histograms above. Below is a visualization of both of these included. The “red” line indicates the mean and the “blue” line indicates the median.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit tracks how many hours he studies each day for two weeks. Help him visualize this data with a histogram.\n\\(2.5,\\ 3.2,\\ 5.4,\\ 7.4,\\ 2.1,\\ 0.5,\\ 1.4,\\ 4.2,\\ 2.1,\\ 3.2,\\ 0,\\ 2.4,\\ 4.4,\\ 5.0\\)\n\n\nClick to see the solution\n\n\n\n\n\nWe can also use visualizations to try and determine if relationships exist between multiple variables. To do this we can use a scatter-plot, which will plot one variable on the \\(x\\)-axis and another variable on the \\(y\\)-axis. The points are plotted as ordered pairs. In future classes we will investigate how to describe the relationship of two variables using mathematics as well as learning how to calculate the line of best fit. Our example has been tweaked a little to include the student enrollment for each college in the conference. We will plot these points to see if a relationship exists between game attendance and student enrollment. We should stress though that just because a relationship exists does not mean that one variable causes the other variable to change. To quote the popular cliche: Correlation does not equal Causation!\nBased on our plot, it appears that as student enrollment has no affect on basketball attendance. This does not make sense, as we would probably expect schools with more students to have more fans at the games. This may indicate that we are missing some other confounding variable that is causing some confusion in our results (like population of the surrounding area or even cost of attendance?).\n\n\n\n\n\nCollege\nMean Attendance\nStudent Enrollment\n\n\n\n\nCanisius\n847\n2630\n\n\nFairfield\n2135\n6298\n\n\nIona\n1822\n3720\n\n\nManhattan\n769\n3195\n\n\nMarist\n2025\n6657\n\n\nMerrimack\n1462\n5505\n\n\nMount St. Mary’s\n1888\n2240\n\n\nNiagara\n855\n3763\n\n\nQuinnipiac\n1510\n9744\n\n\nRider\n1540\n3693\n\n\nSacred Heart\n1209\n6524\n\n\nSaint Peter’s\n539\n3673\n\n\nSiena\n5044\n3623",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Detectives</span>"
    ]
  },
  {
    "objectID": "Lecture-2-Data-Detectives.html#describing-qualitative-data",
    "href": "Lecture-2-Data-Detectives.html#describing-qualitative-data",
    "title": "2  Data Detectives",
    "section": "2.5 Describing Qualitative Data",
    "text": "2.5 Describing Qualitative Data\nEverything we have discussed so far deals with quantitative data. We cannot describe qualitative (categorical) data the same way though, as it will not make sense to calculate and mean or the standard deviation of groups. What we can do though is describe it using counts. The example we have been using throughout this lecture is once again tweaked to include a new column, the state where the University is located, and whether or not the school is Catholic (C) or non-Catholic (NC).\n\n\n\n\n\n\n\n\n\n\n\n\nCollege\nMean Attendance\nStudent Enrollment\nReligious\nState\n\n\n\n\nCanisius\n847\n2630\nCatholic\nNew York\n\n\nFairfield\n2135\n6298\nCatholic\nConnecticut\n\n\nIona\n1822\n3720\nCatholic\nNew York\n\n\nManhattan\n769\n3195\nCatholic\nNew York\n\n\nMarist\n2025\n6657\nNot Catholic\nNew York\n\n\nMerrimack\n1462\n5505\nCatholic\nMassachusetts\n\n\nMount St. Mary’s\n1888\n2240\nCatholic\nMaryland\n\n\nNiagara\n855\n3763\nCatholic\nNew York\n\n\nQuinnipiac\n1510\n9744\nNot Catholic\nConnecticut\n\n\nRider\n1540\n3693\nNot Catholic\nNew Jersey\n\n\nSacred Heart\n1209\n6524\nCatholic\nConnecticut\n\n\nSaint Peter’s\n539\n3673\nCatholic\nNew Jersey\n\n\nSiena\n5044\n3623\nCatholic\nNew York\n\n\n\n\n\nIt is a relatively straightforward procedure, but we can do a count by category and see that 10 schools are Catholic and 3 schools that are not Catholic. We could do something similar with their locations and note that 6 schools are in New York, 3 are in Connecticut, 2 are in New Jersey, 1 is in Maryland, and 1 is in Massachusetts. To visualize categorical data we can use a barplot. This is similar to the histogram but the bars will not touch each other. Below is a visualization for both counts:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can do a “more exciting” analysis with categorical data by calculating quantitative descriptions within their categorical groups. For instance, we could calculate the mean attendance for Catholic schools (1657) and compare it to the mean attendance for non-Catholic schools (1691.67). We could also do something similar for the school’s location:\n\n\n\n\n\nState\nMean Attendance\n\n\n\n\nConnecticut\n1618.000\n\n\nMaryland\n1888.000\n\n\nMassachusetts\n1462.000\n\n\nNew Jersey\n1039.500\n\n\nNew York\n1893.667\n\n\n\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit surveyed 30 students, asking what type of student club they were in and how many hours per week they typically spent participating. Using the information below, help him create a bar chart for the number of students in each club type and then which club type has the highest average time commitment.\n\n\n\nClub Type\nHours per Week (per student)\n\n\n\n\nAcademic\n3, 4, 2, 5, 3\n\n\nSports\n8, 10, 7, 9, 6, 10, 8\n\n\nArts\n5, 4, 6, 5, 7, 4\n\n\nService\n2, 3, 4, 3, 2, 1, 2, 3, 2\n\n\n\n\n\nClick to see the solution\n\n\n\n\n\n\n\n\nGeorge Carlin once said “Think of how stupid the average person is, and realize half of them are stupider than that.” What descriptive statistic is he referencing here?\nWhat is the difference between a bar chart and a histogram?\nFind the mean, median, and mode for the following quiz grades: \\[ 84,\\ 91,\\ 87,\\ 84,\\ 88,\\ 93,\\ 84\\]\nCalculate the standard deviation and range for the following steptotals (in thousands): \\[9,\\ 11,\\ 7,\\ 13,\\ 10,\\ 16\\]\nEmmit surveyed students about their favorite breakfast. Create a visualization to help communicate the fact that 12 students preferred pancakes, 8 preferred bagels, 10 preferred smoothies, and 5 preferred cereal.\nCreate a histogram using bin widths of 5 minutes (0-4.99, 5-9.99, etc.) \\[3,\\ 4,\\ 5,\\ 5,\\ 6,\\ 6,\\ 7,\\ 7,\\ 7,\\ 8,\\ 8,\\ 8,\\ 8,\\ 9,\\ 9,\\ 10,\\ 10,\\ 12,\\ 15,\\ 19\\]\nThe following data describes the number of students in different courses. Calculate the mean study hours for each qualitative group.\n\n\n\n\nMajor\nHours\n\n\n\n\nBiology\n10, 12, 11, 13, 19\n\n\nBusiness\n27, 26, 18, 25, 17\n\n\nSociology\n18, 10, 19, 17, 13",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Detectives</span>"
    ]
  },
  {
    "objectID": "Lecture-3-R-Basics.html",
    "href": "Lecture-3-R-Basics.html",
    "title": "3  R Basics",
    "section": "",
    "text": "3.1 The R Language\nAs Data Scientists, we will not have to calculate everything by hand, but rather we will rely on a statistical programming language called R. This is an open-source language (meaning anyone can contribute to it) designed to clean, analyze, and present data. Before you begin coding in R you should note that syntax rules do apply and it is an interpreted language (meaning you can run it line by line). One of the benefits of R (and why we are learning it) is that it is a popular, powerful, and flexible language used by Data Scientists throughout the industry.\nThe language is maintained by the Comprehensive R Archive Network (CRAN) and can be downloaded from their website CRAN. Since R is an open-source language, community members can write their own programs and submit them to CRAN for the whole community to use. Because of this, R is constantly evolving and you can almost always find a library or a package that will do the analysis you need it to do. If you have not already downloaded R to your device then I would recommend doing so now so that you can follow along with the rest of this lecture. A picture of the R console can be seen below:\nJust because we can run all types of analysis on a dataset does not mean that we should though, as you will not use all of the ingredients in your pantry when you make dinner just because they are available to you. You need to understand what you are doing when you run code or analyze datasets. You should know what your dataset contains and the different data types that you have. You should know the quality of your data and if there are any underlying problems with the dataset, and you should know if any relationships might exist within the dataset.\nKnowing all of these things will not only help us in writing code to analyze the data, but it will make our lives easier and save us time. A famous phrase (possibly coined by Army specialist William Mellin) tells us “Garbage in… Garbage out”. He expanded on this phrase with the following explanation: “If the problem has been sloppily programmed the answer will be just as incorrect. If the programmer made mistakes the machine will make mistakes. It can’t correct them because it can’t do one thing: It can’t think for itself.”",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "Lecture-3-R-Basics.html#starting-to-code",
    "href": "Lecture-3-R-Basics.html#starting-to-code",
    "title": "3  R Basics",
    "section": "3.2 Starting to Code",
    "text": "3.2 Starting to Code\nThe R Console will be where we will “submit” our code to be run line by line. Any code you wish to run should be placed after the &gt; symbol. Let’s open up R and type in Hello R and see what happens. We should get an error telling us that there is an unexpected symbol present. This is because R does not understand what the word Hello means. If we want to type in characters/words/strings then we need to do so inside of quotation marks (either “double” quotes or ‘single’ quotes). Below is an example of what your results may look like. Note that the grey box seen below will represent the R console to display the code/output.\n\nHello R\n\nError: unexpected symbol in \"Hello R\"\n\n\"Hello R\"\n\n[1] \"Hello R\"\n\n'Hello R'\n\n[1] \"Hello R\"\n\n\nBefore we continue running code in R, it is important to go over some quick housekeeping notes. To begin, you will place your code after the &gt; symbol. If you see a + on the left-hand side, it means that R is expecting something more to end the previous line (maybe you are missing a quotation mark or parenthesis). Anything you put after # will be considered a comment and nothing on the line after the # symbol will run. It is also important to realize that R is case sensitive so MyData and mydata are different. If you ever would like to access any previous commands then you can have them re-appear by using the up and down arrows on your keyboard. Finally, if you are ever unsure about the exact command syntax then R will help you finish typing the commands (tab completion).\n\n&gt; \"I am Dr. McCurdy\n+ and I forgot a quotation mark\"\n\n\n\n[1] \"I am Dr. McCurdy\\nand I forgot a quotation mark\"\n\n\n\n# Words after the pound sign will not run since it is a comment\n2 + 3 # Adding 2 numbers together\n\n[1] 5\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit is running a smoothie stand on campus and he can’t quite figure out how to advertise his business in R. He wants to calculate the price ($2 + $1 for each size increase) and make a digital sign that displays this message in R: “Welcome to Emmit’s Smoothie Stand!” How can he accomplish this task?\n\n\nClick to see the solution",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "Lecture-3-R-Basics.html#understanding-error-messages",
    "href": "Lecture-3-R-Basics.html#understanding-error-messages",
    "title": "3  R Basics",
    "section": "3.3 Understanding Error Messages",
    "text": "3.3 Understanding Error Messages\nIt is also probably time to discuss some of the things that can go wrong when inputting code. The first that might occur (and the most obvious) is a syntax error. This means that you have submitted invalid code (maybe a forgotten comma, an “open” bracket, or misspelled a function name/variable) and R returns an error message. It is important to read the error message! About 95% of the time it will be easy to identify your mistake and fix it. We will see some common syntax errors later on in the course as we get to new material.\nAnother error that you might make is a semantic error. This occurs when your code is technically correct but it does not do what you expected it to do. For instance, if you are trying to find the mean of a dataset with 10 items and you divide by 11 instead, then R will run it just fine, but you didn’t calculate the mean. These semantic errors are hard to find and figure out, but it does help to run your code line by line to identify where the unexpected result occurs. When in doubt explain your code to a rubber duck! (this means that looking at your code line by line and trying to explain it usually helps you identify the mistake)\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit is trying to figure out how many customers he usually gets in a day but he does not think the result makes sense. The past 7 days he has had the following numbers: 14, 18, 21, 19, 17, 23, 20. Looking at the following code, help him determine his average daily customer count:\n&gt; 14 + 18 + 21 + 19 + 17 + 23 + 20) / 8\n\n\nClick to see the solution",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "Lecture-3-R-Basics.html#using-r-as-a-calculator",
    "href": "Lecture-3-R-Basics.html#using-r-as-a-calculator",
    "title": "3  R Basics",
    "section": "3.4 Using R as a Calculator",
    "text": "3.4 Using R as a Calculator\nTo get started with R, we should think of it as a calculator. Any mathematical operations we wish to do we can. Below are a few examples of the commands we can use:\n\n# Addition and Subtraction: use + and -\n7 + 3 - 19 + 8\n\n[1] -1\n\n# Multiplication and Division: use * and /\n3 * 8 / 7\n\n[1] 3.428571\n\n# Exponentiation: use ^\n4 ^ 5\n\n[1] 1024\n\n# Parenthesis for grouping calculated expressions: use ()\n(3 + 5)/3\n\n[1] 2.666667\n\n# Integer Division (floor): use %/%\n18 %/% 7\n\n[1] 2\n\n# Modulus (remainder): use %%\n18 %% 7\n\n[1] 4\n\n# Example showing how the floor and remainder function work:\n18/7\n\n[1] 2.571429\n\n18 %/% 7 + 18%%7 / 7\n\n[1] 2.571429\n\n\nR follows the standard Order of Operations, with the order going P-E-%-MD-AS. This means that R will always carry out items in the Parenthesis before going on to things outside of the parenthesis. Next, R will look for Exponentiation, with the operations being carried out from right to left. This means that \\(2 \\wedge 2 \\wedge 3\\) is not \\(4 \\wedge 3\\) but rather \\(2\\wedge8\\). Any special function indicated with a % will be next. Then Multiplication and Division are evaluated left to right (which is typical) with Addition and Subtraction being evaluated last (also left to right). It may take some getting used to, so I always recommend putting more parenthesis than is required so that you can have peace of mind that the calculation is what you intended it to be.\nFor values that contain a certain number of significant figures (usually more than 7), R will represent the results in scientific notation. This is represented with an \\(e\\), which stands for \\(\\times 10^n\\). For instance, \\(3.21\\times 10^{-7}\\) is represented in R as \\(3.21e-7\\).\n\n102938303820387203828373\n\n[1] 1.029383e+23\n\n.00000002828\n\n[1] 2.828e-08\n\n2.31e-2\n\n[1] 0.0231\n\n3.9282e12\n\n[1] 3.9282e+12\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit is competing in a local math scavenger hunt. He finds a list of strange math expressions written on a whiteboard and he decides to use R to carry out the calculations. What should the results be for each expression?\n\n\\(\\displaystyle 10^2 + \\frac{3\\times 60}{8 + 3} - 3\\)\n\\(\\displaystyle \\frac{5^3\\times(6-2)}{61-3+4}\\)\n\\(\\displaystyle \\left(\\frac{2^{2+1}}{6^{-2^{2.5}}}\\right)^\\frac{1}{2}\\)\n\n\n\nClick to see the solution",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "Lecture-3-R-Basics.html#variables",
    "href": "Lecture-3-R-Basics.html#variables",
    "title": "3  R Basics",
    "section": "3.5 Variables",
    "text": "3.5 Variables\nIn addition to using R as a calculator, we can also save values as variables. Variables will allow us to provide a reference (a name) so that we can reuse the value later. To create a variable we will use the \\(&lt;\\)- operator (also called the assignment operator) with the value we want to save “pointing” at the variable name. Like everything else in R, variables are case-sensitive so we should make them short and meaningful so that they are easy to type in over and over. We will be able to name them (almost) anything we want, as the names can contain letters, numbers, periods, or even underscores.\n\nvalue1 &lt;- 3\nvalue2 &lt;- 5\nvalue1\n\n[1] 3\n\nvalue1 + value2\n\n[1] 8\n\n\n\nvalue3 # will have a syntax error since value3 does not exist\n\nError: object 'value3' not found\n\nvalue3 &lt;- value1*value2\nvalue3\n\n[1] 15\n\n\nThese variables will allow us to save results for later use. If we anticipate having to type in a calculation multiple times then we might as well create a variable (type once; use often). It should be mentioned that some variable names are “off-limit”, such as the name of R functions and commands. We will discuss that later in more detail though.\n\nx &lt;- 1*2 + 3*4 + 5*6 + 7*8\ny &lt;- 9^3 + 8^3\nz &lt;- (5 + 3^2) ^2\n\nx * y\n\n[1] 124100\n\ny / z\n\n[1] 6.331633\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit is running a smoothie stand at the weekend farmer’s market. He sells two types of smoothies: Berry Blast and Tropical Twist. Each Berry Blast sells for $4 and each Tropical Twist sells for $5. On Saturday, he sold 9 Berry Blasts and 6 Tropical Twists. Let’s help Emmit calculate how much money he made using R using variables.\n\n\nClick to see the solution",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "Lecture-3-R-Basics.html#the-r-environment",
    "href": "Lecture-3-R-Basics.html#the-r-environment",
    "title": "3  R Basics",
    "section": "3.6 The R Environment",
    "text": "3.6 The R Environment\nWe interact with R through environments. Think of it as filing cabinets. If we define a variable called x in one drawer (let’s call it Drawer 1), then when we open up Drawer 2 we will not be able to find x. This is because it is not in Drawer 2, it is in Drawer 1. This is known as a workspace, and most of the time we will be defining variables in the global environment, so we will not have to worry about different drawers. But, any variable that we initialize in R will remain in R as long as our session is still active. We can see what variables and objects currently exist in our environment with the ls() function.\n\nls()\n\n[1] \"value1\" \"value2\" \"value3\" \"x\"      \"y\"      \"z\"     \n\nls(pattern=\"^val\") # can search for certain patterns\n\n[1] \"value1\" \"value2\" \"value3\"\n\n\nIf we ever need to remove a specific object in R from our workspace then we can do this with the rm() function. We should be careful with this though, as we cannot reverse the removal of a variable. If we need to clear our whole workspace then we can remove all objects with rm(list=ls()).\n\nx\n\n[1] 100\n\nrm(x)\n\n\nx\n\nError: object 'x' not found\nIf you need to close R then you can either close it by using the command q() or by just exiting the window. When you close R it will ask you if you want to “Save workspace image?”. What this is asking is if you would like to save all of your current objects in R (all of the variables and functions you have made) and have them available to you in your future R sessions. If you select yes then it will be saved under your current directory under the file .RData. Most things we will be doing in this class will not need to be saved in this manner as it will be easy to recreate everything quickly if we do need something again.\n\n\n\nWhat is the purpose of parentheses in R calculations? Give an example where parentheses change the result of an expression.\nWrite the following expression in R syntax:\n\\(\\left(3 + \\frac{12\\times 2}{2+1}\\right)^2 - 5^2\\)\nCreate a variable called price and assign it the value 4.25. Then create another variable called quantity with the value 6. Create a third variable total that multiplies price by quantity. What is the value of total?\nAfter creating the variable total in the previous problem, use the rm() function to remove total from your environment. What happens if you try to display total after removing it?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "Lecture-7-Dataframes-in-R.html",
    "href": "Lecture-7-Dataframes-in-R.html",
    "title": "7  Dataframes in R",
    "section": "",
    "text": "7.1 Creating Dataframes\nWithin R, we can form structured data with multiple columns. These are called Dataframes and are comparable to the way a spreadsheet may look. Within each dataframe, multiple columns can be present, with each column being a vector. Additionally, the column types may vary, as we can have a numeric vector, a logical vector, and a character vector all in the same dataframe. It is important to talk about dataframes as this is the predominant data structure in R. Almost all of the datasets that we encounter will be formatted as a dataframe.\nWithin a dataframe, the rows will represent an observation. Additionally, each vector (column) will have the same length as all of the others, resulting in a “rectangular” looking dataframe. We can make one ourselves by specifying the vectors in the data.frame() function. An example of this can be seen below:\nx &lt;- 12:16\ny &lt;- 80:84\ndf &lt;- data.frame(x,y)\ndf\n\n   x  y\n1 12 80\n2 13 81\n3 14 82\n4 15 83\n5 16 84\nAnother example can be seen below. In creating this dataframe we will utilize our sample() function to randomly generate a vector of length 10. When you run the same code you might have different values generated since it does so randomly. To display it I will use the head() function will display just the first few observations:\nnames &lt;- sample(c(\"John\", \"Paul\", \"George\", \"Ringo\"), 10, replace=TRUE)\nages &lt;- sample(18:25, 10, replace=TRUE)\nmajor &lt;- sample(c(\"Undeclared\", \"Math\", \"Cyber\", \"Data\", \"Comp-Sci\"), 10, replace=TRUE)\ncommuter &lt;- sample(c(TRUE, FALSE), 10, replace=TRUE)\ndf &lt;- data.frame(names, ages, major, commuter)\nhead(df, 5) # Retrieves the first 5 rows (6 by default)\n\n   names ages    major commuter\n1   John   24     Math     TRUE\n2  Ringo   19    Cyber    FALSE\n3   John   20     Data     TRUE\n4 George   19     Data     TRUE\n5  Ringo   18 Comp-Sci    FALSE",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Dataframes in R</span>"
    ]
  },
  {
    "objectID": "Lecture-7-Dataframes-in-R.html#the-structure-of-dataframes",
    "href": "Lecture-7-Dataframes-in-R.html#the-structure-of-dataframes",
    "title": "7  Dataframes in R",
    "section": "7.2 The Structure of Dataframes",
    "text": "7.2 The Structure of Dataframes\nOne nice thing about dataframes is that the individual columns will retain the same class type that the vector has. We can see the structure of the dataframe by passing the dataframe into the str() function.\n\nstr(df)\n\n'data.frame':   10 obs. of  4 variables:\n $ names   : chr  \"John\" \"Ringo\" \"John\" \"George\" ...\n $ ages    : int  24 19 20 19 18 20 21 18 19 21\n $ major   : chr  \"Math\" \"Cyber\" \"Data\" \"Data\" ...\n $ commuter: logi  TRUE FALSE TRUE TRUE FALSE FALSE ...\n\n\nWe can also bind vectors together using the cbind() function, but we should be weary about this as the vector types will be altered to the “lowest” type if they are different. The function name cbind() stands for column bind, which will attach a new column on the end of another vector/dataframe. An example of this can be seen below where all of the columns are turned into characters\n\ndf2 &lt;- data.frame(cbind(names, ages, major, commuter))\nhead(df2,5)\n\n   names ages    major commuter\n1   John   24     Math     TRUE\n2  Ringo   19    Cyber    FALSE\n3   John   20     Data     TRUE\n4 George   19     Data     TRUE\n5  Ringo   18 Comp-Sci    FALSE\n\nstr(df2)\n\n'data.frame':   10 obs. of  4 variables:\n $ names   : chr  \"John\" \"Ringo\" \"John\" \"George\" ...\n $ ages    : chr  \"24\" \"19\" \"20\" \"19\" ...\n $ major   : chr  \"Math\" \"Cyber\" \"Data\" \"Data\" ...\n $ commuter: chr  \"TRUE\" \"FALSE\" \"TRUE\" \"TRUE\" ...\n\n\nWe can also attach a new row on the end of a dataframe using the rbind() function. Once again though, we should be wary about this as we can potentially alter the column types.\n\ndata_to_be_added &lt;- c(\"Pete\", 24, \"Percussion\", FALSE)\ndf_added &lt;- rbind(df, data_to_be_added)\ntail(df_added, 5) # Retrieves the last 5 observations of the dataframe\n\n    names ages      major commuter\n7    John   21       Math     TRUE\n8    John   18 Undeclared    FALSE\n9   Ringo   19 Undeclared     TRUE\n10 George   21       Data     TRUE\n11   Pete   24 Percussion    FALSE\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nUsing the dataframe you previously made for Emmit, add a new row to the list of attendees: Gracie who is 39, a speaker, and not registered.\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Dataframes in R</span>"
    ]
  },
  {
    "objectID": "Lecture-7-Dataframes-in-R.html#dataframe-properties",
    "href": "Lecture-7-Dataframes-in-R.html#dataframe-properties",
    "title": "7  Dataframes in R",
    "section": "7.3 Dataframe Properties",
    "text": "7.3 Dataframe Properties\nWe can learn about the dataframe’s properties using a few different functions. One function called dim() will tell us about the number of rows and columns in the dataset (the dimension). Meanwhile, nrow() will tell us the number of rows, and ncol() will tell us the number of columns in the dataframe.\n\ndim(df)\n\n[1] 10  4\n\nnrow(df)\n\n[1] 10\n\nncol(df)\n\n[1] 4\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nUsing the dataframe you previously made for Emmit with Gracie now added, determine the number of rows and columns the dataframe has.\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Dataframes in R</span>"
    ]
  },
  {
    "objectID": "Lecture-7-Dataframes-in-R.html#column-names-for-dataframes",
    "href": "Lecture-7-Dataframes-in-R.html#column-names-for-dataframes",
    "title": "7  Dataframes in R",
    "section": "7.4 Column names for Dataframes",
    "text": "7.4 Column names for Dataframes\nSometimes it is helpful to re-name the columns of a dataframe if we do not like the current names of the vector. We can do this when we create the dataframe like in the example below:\n\nx &lt;- 0:9\ny &lt;- 10:19\nz &lt;- 20:29\n\ndf3 &lt;- data.frame(\"singles\"=x, \"tens\"=y, \"twenties\"=z)\nhead(df3)\n\n  singles tens twenties\n1       0   10       20\n2       1   11       21\n3       2   12       22\n4       3   13       23\n5       4   14       24\n6       5   15       25\n\n\nIf we do not name them during the creation of the dataframe or we have a dataframe already in R and we want to rename the column names then we can do this using the colnames() function.\n\ndf3 &lt;- data.frame(x,y,z)\ncolnames(df3)\n\n[1] \"x\" \"y\" \"z\"\n\ncolnames(df3) &lt;- c(\"singles\", \"tens\", \"twenties\")\nhead(df3,4)\n\n  singles tens twenties\n1       0   10       20\n2       1   11       21\n3       2   12       22\n4       3   13       23\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit decides that the dataframe for the conference should have different header names. Alter the dataframe so the column names are now: “participant_name”, “participant_age”, “conference_role”, and “paid”.\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Dataframes in R</span>"
    ]
  },
  {
    "objectID": "Lecture-7-Dataframes-in-R.html#dataframe-index-selection",
    "href": "Lecture-7-Dataframes-in-R.html#dataframe-index-selection",
    "title": "7  Dataframes in R",
    "section": "7.5 Dataframe Index Selection",
    "text": "7.5 Dataframe Index Selection\nAccessing dataframe elements will be similar to accessing vector elements except now we are dealing with a 2-dimensional object in R. Thus, we will need to specify both dimensions (row and column). You will hear me say over and over again in class: “Dataframes index by Row comma Column”. Within our index selection brackets, we will need to have the comma present. If we put nothing before the comma it will indicate all rows, while nothing after the comma will indicate all columns.\nIf we would wish to display the element in the second row and first column we would make sure we call our dataframe and then in the index selection brackets we would say ‘[2,1]’. If we wanted to display the 3rd observation (3rd row) then we could just say ‘[3,]’ in our index-selection brackets. To display all of the elements in the 2nd column we would say ‘[,2]’ in our index-selection brackets. An example of this can be seen below:\n\nhead(df, 4)\n\n   names ages major commuter\n1   John   24  Math     TRUE\n2  Ringo   19 Cyber    FALSE\n3   John   20  Data     TRUE\n4 George   19  Data     TRUE\n\ndf[2,1] # Element in the 2nd row and 1st column\n\n[1] \"Ringo\"\n\ndf[3,] # Elements in the 3rd row\n\n  names ages major commuter\n3  John   20  Data     TRUE\n\ndf[,2] # Elements in the 2nd column\n\n [1] 24 19 20 19 18 20 21 18 19 21\n\n\nWe can also retrieve elements in a column by using a dollar sign ($) and then typing the column name. This resulting output will be a vector, not a dataframe, and will contain all of the values in that column.\n\ndf$names\n\n [1] \"John\"   \"Ringo\"  \"John\"   \"George\" \"Ringo\"  \"George\" \"John\"   \"John\"  \n [9] \"Ringo\"  \"George\"\n\ndf$ages\n\n [1] 24 19 20 19 18 20 21 18 19 21\n\ndf$major\n\n [1] \"Math\"       \"Cyber\"      \"Data\"       \"Data\"       \"Comp-Sci\"  \n [6] \"Data\"       \"Math\"       \"Undeclared\" \"Undeclared\" \"Data\"      \n\ndf$commuter\n\n [1]  TRUE FALSE  TRUE  TRUE FALSE FALSE  TRUE FALSE  TRUE  TRUE\n\n\nWe can retrieve multiple rows and/or columns by passing a vector into our index-selection brackets. It should also be noted that we can select vector elements on a vector result. Additionally, we can pass a logical vector into the index-selection brackets to display values that meet certain criteria. Examples of these can be seen below:\n\ndf[3:5, c(1,3)] # Rows 3 through 5 and columns 1 and 3 \n\n   names    major\n3   John     Data\n4 George     Data\n5  Ringo Comp-Sci\n\ndf$ages\n\n [1] 24 19 20 19 18 20 21 18 19 21\n\ndf$ages[2:4]\n\n[1] 19 20 19\n\ndf$ages &lt;= 21\n\n [1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\ndf[df$ages &lt;= 21, ] # Displays just the TRUE rows\n\n    names ages      major commuter\n2   Ringo   19      Cyber    FALSE\n3    John   20       Data     TRUE\n4  George   19       Data     TRUE\n5   Ringo   18   Comp-Sci    FALSE\n6  George   20       Data    FALSE\n7    John   21       Math     TRUE\n8    John   18 Undeclared    FALSE\n9   Ringo   19 Undeclared     TRUE\n10 George   21       Data     TRUE\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit would like to display some key information from the conference attendees. First he would like to display all of the people that are speaking, then he would like to display all of the people who are under the age of 35, and finally he would like to display all of the people who are either attendees and have paid the registration fee.\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Dataframes in R</span>"
    ]
  },
  {
    "objectID": "Lecture-7-Dataframes-in-R.html#editing-a-dataframe",
    "href": "Lecture-7-Dataframes-in-R.html#editing-a-dataframe",
    "title": "7  Dataframes in R",
    "section": "7.6 Editing a Dataframe",
    "text": "7.6 Editing a Dataframe\nFinally, we can remove a single row or column from our dataframe, but we want to be very careful of doing this as we might not be able to reverse the action. To remove a row or column we can simply overwrite our dataframe by stating our dataframe and then in our index-selection brackets indicate which row/column you want to remove with a negative sign. Both methods can be seen below:\n\ndf4 &lt;- df[-2,] # Everything but the second row\nhead(df4,3)\n\n   names ages major commuter\n1   John   24  Math     TRUE\n3   John   20  Data     TRUE\n4 George   19  Data     TRUE\n\ndf4 &lt;- df[,-3] # Everything but the third column\nhead(df4,3)\n\n  names ages commuter\n1  John   24     TRUE\n2 Ringo   19    FALSE\n3  John   20     TRUE\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit decides that he does not need to record the attendee’s age. He also found out that Adam is withdrawing from the conference. Help him remove the age column from the dataframe along with Adam’s information.\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX\n\n\n\n\n\nCreate a dataframe in R pertaining to cities in New York:\n\nA vector called cities with “Albany”, “Buffalo”, “Syracuse”, “Rochester”, “Ithaca” all included\n\nA vector called population with the values 97500, 255000, 142000, 210000, 32000\nA logical vector called capital with Albany set to True and the rest being False\nDisplay the structure of the dataframe.\nAdd a new column using cbind() called temperature with the values: 48,46,47,49,45.\nUse rbind() to add the row: “Binghamton”, 47000, FALSE, 44.\nExplain what happens to the column types after adding the row.\n\nCreate a dataframe in R pertaining to states on the East Coast:\n\nA vector containing the following states: “NY”, “MD”, “PA”, “NJ”, “VA”\nA vector containing the following median income values: 75000, 88000, 68000, 85000, 72000\nA logicial vector based on if it is a costal state (only Pennsylvania is not on the coast)\nDisplay all of the costal states\nDisplay all of the rows where the median income is greater than 80000\nDisplay all of the rows where the state ends in a vowel or has a median income less than 77000",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Dataframes in R</span>"
    ]
  },
  {
    "objectID": "Lecture-1-What-is-Data.html#data-fication",
    "href": "Lecture-1-What-is-Data.html#data-fication",
    "title": "1  What is Data?",
    "section": "",
    "text": "Reflection\n\n\n\nBefore reading on, you should stop and think about what information about you is out there.\n\nCan you think of specific companies/groups which have a lot of data bout you?\nDo you think it is a good or bad thing that information about you is collected?\n\n\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit is a college sophomore who starts every day by checking his phone, grabbing a breakfast burrito at the cafeteria, and hiking to the Grotto on campus. What types of data are being generated by Emmit’s morning routine? Who might collect that data, and what could they use it for?\n\n\nClick to see the solution",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Data?</span>"
    ]
  },
  {
    "objectID": "Lecture-4-R-and-Vectors.html",
    "href": "Lecture-4-R-and-Vectors.html",
    "title": "4  Vectors and Factors in R",
    "section": "",
    "text": "4.1 Data Types in R\nAs we continue learning R, it’s important to understand how data is structured and stored. In R, everything is a vector, this includes not only sequences of numbers but also text and logical values. This design choice makes R a powerful tool for performing operations across entire datasets at once. In this section, we will explore how to create, manipulate, and understand vectors, as well as how to work with factors, which are special types of vectors used to represent categorical data. Understanding these structures will be foundational to all future data analysis you perform in R.\nSo far we have seen how we can create variables in R. It is important to note that all objects in R have a type (the big three are Doubles, Characters, and Logical). A benefit to R is that we do not have to declare each variable and type, as it can figure all of that information out without us needing to do anything. Doubles consist of our numbers, which can be integers or decimal values. This is not the same as floating point values in other languages though. We can coerce the value to be an integer by placing an “L” after it (but there is no real benefit right now for integers over doubles so don’t worry about it). Characters will be anything in quotes, whether it is a single letter, a word, a paragraph, a symbol, or a number. R will treat all characters the same. The last type we should discuss is the Logical type, which consists of TRUE and FALSE (yes it has to be in all caps) or the shortened T and F. If we are ever unsure of the type we are dealing with, we can use the typeof() function and R will tell us.\ntypeof(17.2)\n\n[1] \"double\"\n\ntypeof(17L)\n\n[1] \"integer\"\n\ntypeof(17)\n\n[1] \"double\"\n\ntypeof(\"17\")\n\n[1] \"character\"\n\ntypeof(TRUE)\n\n[1] \"logical\"\nIt is critical to know what type our value is as it will determine what functions we can use, how we compose expressions, and how we will interpret the results. For instance, we cannot do “math” on characters but we can do “math” with doubles and logicals (though it might not always make sense to do this).\n\"a\" + \"b\"\nError in \"a\" + \"b\" : non-numeric argument to binary operator\n3 + TRUE # TRUE is equal to 1 and FALSE is equal to 0\n\n[1] 4\n\"abc\" + 2\nError in \"abc\" + 2 : non-numeric argument to binary operator\nOne thing that makes R different then some other languages is that R is “vectorized” (meaning everything is a vector). This characteristic will allow us to quickly work with entire sets of data and avoids the need for iterations or loops (but the for and while loop still exist). So remember, Everything is a Vector!!!",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vectors and Factors in R</span>"
    ]
  },
  {
    "objectID": "Lecture-4-R-and-Vectors.html#vectors",
    "href": "Lecture-4-R-and-Vectors.html#vectors",
    "title": "4  Vectors and Factors in R",
    "section": "4.2 Vectors",
    "text": "4.2 Vectors\nTo create a vector containing multiple elements we will use the combine function \\(c()\\). This will allow us to combine multiple single-element vectors into a multi-element vector. An example of this process can be seen below:\n\nx &lt;- c(1,2,3,4)\nx\n\n[1] 1 2 3 4\n\ny &lt;- c(\"Hello\", \"my name is\", \"Dr. McCurdy\")\ny\n\n[1] \"Hello\"       \"my name is\"  \"Dr. McCurdy\"\n\n\nIf we create a vector with multiple types of data in it then it reverts to the “lowest” one present (character \\(&lt;\\) double \\(&lt;\\) logical). So, if at least one character is present then all of the elements are turned into characters, and if no characters are present but a double is then all elements turn into doubles. We can see the type a vector is using the class() function.\n\nx &lt;- c(1,2,\"3\",4,5) # One character is present\nclass(x)\n\n[1] \"character\"\n\nx\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\ny &lt;- c(1, 2, TRUE, 4, 5) # TRUE is turned into a 1\nclass(y)\n\n[1] \"numeric\"\n\ny\n\n[1] 1 2 1 4 5\n\n\nIf we need to explicitly coerce a vector to be a certain type we can (for the most part). It is the nature of vectors to apply functions on every element, so using a function like as.numeric() or as.character() will try and force all elements to become a certain type.\n\nx &lt;- as.numeric(c(1,2,\"3\",4,5)) # 3 is coerced into a number\nclass(x)\n\n[1] \"numeric\"\n\nx\n\n[1] 1 2 3 4 5\n\ny &lt;- as.character(c(1,2,3,4,5)) # All items are coerced into characters\nclass(y)\n\n[1] \"character\"\n\ny\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\n\nWhenever we are dealing with vectors it is important to resist the urge to fight the vector’s nature. That is, don’t try and overthink it or make it more difficult for yourself, R was meant to handle vectors. All arithmetic operators can be used on vectors. It will apply the operation between comparable elements and will “recycle” the shorter vector if needed.\n\nx &lt;- c(1,2,3,4,5)\nx\n\n[1] 1 2 3 4 5\n\nx + 13\n\n[1] 14 15 16 17 18\n\nx * -2\n\n[1]  -2  -4  -6  -8 -10\n\nx &lt;- c(1,2,3)\ny &lt;- c(5,6,7)\n\nx + y\n\n[1]  6  8 10\n\nx^y\n\n[1]    1   64 2187\n\nx &lt;- c(1,2,3,4,5)\ny &lt;- c(1,10,100)\nx + y\n\nWarning in x + y: longer object length is not a multiple of shorter object\nlength\n\n\n[1]   2  12 103   5  15\n\n\nWe can also make vectors that are not numeric. These can be both character strings or logical values.\n\nx &lt;- c(\"this\", \"is\", \"a\", \"character vector!\")\nx\n\n[1] \"this\"              \"is\"                \"a\"                \n[4] \"character vector!\"\n\ny &lt;- \"this is also a character vector!\"\ny\n\n[1] \"this is also a character vector!\"\n\nz &lt;- c(T, T, F, F, T, F, T)\nz\n\n[1]  TRUE  TRUE FALSE FALSE  TRUE FALSE  TRUE\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit writes the amount of money he spends on coffee each day for a whole week. Help him put the values in a vector and then determine the prices if they increase by 25%.\n\\(\\$4.25,\\ \\$0,\\ \\$3.75,\\ \\$4.00,\\ \\$5.00,\\ \\$2.75,\\ \\$3.00\\)\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vectors and Factors in R</span>"
    ]
  },
  {
    "objectID": "Lecture-4-R-and-Vectors.html#logical-operators",
    "href": "Lecture-4-R-and-Vectors.html#logical-operators",
    "title": "4  Vectors and Factors in R",
    "section": "4.3 Logical Operators",
    "text": "4.3 Logical Operators\nOne of the most important things we do in this class (and we will repeatedly do it throughout the semester) is using logical operators on vectors. If we compare 2 vectors using logical operators, the result will be a logical vector. There are a few big ones that we will need to know, and they are pretty well known. For instance, \\(&lt;\\) means less than, \\(&gt;\\) means greater than, \\(&lt;=\\) means less than or equal, \\(&gt;=\\) means greater than or equal, \\(==\\) means equal (notice it is two equal signs), and \\(!=\\) means not equal.\n\nx &lt;- c(0, 4, 2, 5, 3, 6)\nx\n\n[1] 0 4 2 5 3 6\n\nx == 3 # Checks each element to see if it is equal to 3\n\n[1] FALSE FALSE FALSE FALSE  TRUE FALSE\n\nx &gt; 4 # Checks each element to see if it is greater than 4\n\n[1] FALSE FALSE FALSE  TRUE FALSE  TRUE\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit is training for a marathon and tracks how many miles he runs each day for a week. Using logical vectors determine which days Emmit ran exactly 5 miles, which days he ran more than 4 miles, and which days his total was not equal to 6 miles.\nmileage: \\(6,\\ 5,\\ 6,\\ 2,\\ 4,\\ 12,\\ 5\\)\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vectors and Factors in R</span>"
    ]
  },
  {
    "objectID": "Lecture-4-R-and-Vectors.html#built-in-statistical-functions",
    "href": "Lecture-4-R-and-Vectors.html#built-in-statistical-functions",
    "title": "4  Vectors and Factors in R",
    "section": "4.4 Built-in statistical functions",
    "text": "4.4 Built-in statistical functions\nWithin R, there are also built-in functions that will make our lives easier. All of the functions in this section will require us to pass a vector into it and it will output a vector of the same size or of size 1 or 2. The names for these functions resemble the function name that we would say out loud.\n\nsqrt(182) # square-root of 182\n\n[1] 13.49074\n\nx &lt;- c(2,49,381)\nsqrt(x)\n\n[1]  1.414214  7.000000 19.519221\n\nlog(x)\n\n[1] 0.6931472 3.8918203 5.9427994\n\n\nThere are also functions in R that will do all of the calculations we did in the earlier lectures. Unfortunately, there is no function to calculate the mode of a dataset. When working with these functions, it is important to make sure we pass a vector into the functions (this is a common error students make when they start off).\n\nx &lt;- c(12, 10, 18, 11, 11, 15, 21)\n\nsum(x)\n\n[1] 98\n\nmean(x)\n\n[1] 14\n\nmedian(x)\n\n[1] 12\n\nsd(x)\n\n[1] 4.163332\n\n\nWe can determine how long a vector is using the function. We could then use this function along with the sum function to calculate the mean of the dataset:\n\nlength(4)\n\n[1] 1\n\nlength(c(4,8,2))\n\n[1] 3\n\nlength(x)\n\n[1] 7\n\nsum(x)/length(x) # Notice this is the mean we found above\n\n[1] 14\n\n\nIn addition to this, we can calculate the minimum, maximum, and range difference of a vector. We say range difference since the range() function provides both the minimum and maximum value, while the diff() function gives us the difference between the two values:\n\nx\n\n[1] 12 10 18 11 11 15 21\n\nsort(x)\n\n[1] 10 11 11 12 15 18 21\n\nmin(x)\n\n[1] 10\n\nmax(x)\n\n[1] 21\n\nrange(x)\n\n[1] 10 21\n\ndiff(range(x))\n\n[1] 11\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit recorded the number of minutes he spent reading each day over the last week:\nreading time: \\(20,\\ 35,\\ 28,\\ 40,\\ 30,\\ 33,\\ 45\\)\n\nWhat is the total time Emmit spent reading?\nWhat was his average (mean) reading time?\nWhat was the median amount of time he read?\nWhat is the standard deviation of his reading time?\nWhat are the minimum and maximum reading times? What is the range difference?\n\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vectors and Factors in R</span>"
    ]
  },
  {
    "objectID": "Lecture-4-R-and-Vectors.html#indexing-in-r",
    "href": "Lecture-4-R-and-Vectors.html#indexing-in-r",
    "title": "4  Vectors and Factors in R",
    "section": "4.5 Indexing in R",
    "text": "4.5 Indexing in R\nThe last big thing we want to mention about vectors is how the elements are indexed. R starts indexing at 1 (this means the first element is index 1, the second element is index 2, and so on) which is different then other languages which start counting at 0. To access specific values we can place the indices in brackets. I will often refer to these as our “Index-Selection” brackets. We must pass a vector into our index-selection brackets using the combine function c() if we have multiple elements that we want to display.\n\nx\n\n[1] 12 10 18 11 11 15 21\n\nx[2]\n\n[1] 10\n\nx[length(x)]\n\n[1] 21\n\nx[c(1,3,6)]\n\n[1] 12 18 15\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit is tracking the number of hours he sleeps each night for a week:\nsleep time: \\(6.5,\\ 7,\\ 8,\\ 6,\\ 7.5,\\ 9,\\ 6.5\\)\n\nHow many hours did Emmit sleep on the second night?\nHow many hours did he sleep on the last night of the week?\nUse indexing to display only the second, fourth, and sixth nights.\nEmmit wants to find the average of the sleep hours from the 2nd, 3rd, and 7th nights.\n\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vectors and Factors in R</span>"
    ]
  },
  {
    "objectID": "Lecture-4-R-and-Vectors.html#creating-factors-in-r",
    "href": "Lecture-4-R-and-Vectors.html#creating-factors-in-r",
    "title": "4  Vectors and Factors in R",
    "section": "4.6 Creating Factors in R",
    "text": "4.6 Creating Factors in R\nSo far we have seen a couple of different types of data in R, including numeric, logical, and character types. Another type that we will use quite a bit are factors. Factors will allow us to represent categorical data that fit in only a finite number of distinct categories. These factors could either be words (like Small, Medium, or Large) or numbers (like a house having 1, 2, or 3 bedrooms). R does some things behind the scenes to make it efficient to store this qualitative data, but the only thing we really need to know is that if we have categorical data then we should probably save it as a factor using the factor() function.\nLet’s create a vector containing a random sample of “Males” and “Females” using the sample() function. First, we should realize that this is categorical data, so we will want to convert it to a factor. We can then use the factor() function to convert it to categories. Notice how the levels are in alphabetical order.\n\nx &lt;- sample(c(\"Male\", \"Female\"), 7, replace=TRUE)\nx\n\n[1] \"Female\" \"Male\"   \"Female\" \"Female\" \"Female\" \"Female\" \"Female\"\n\nfx &lt;- factor(x)\nfx\n\n[1] Female Male   Female Female Female Female Female\nLevels: Female Male\n\n\nWe can also notice how the vector class and the element type are also altered. We don’t have to understand the “behind-the-scenes” happenings of why the element type is now an integer. But we should emphasize though that the new vector is no longer a character vector, rather it is a factor since it is categorical data.\n\nclass(x)\n\n[1] \"character\"\n\nclass(fx)\n\n[1] \"factor\"\n\ntypeof(x)\n\n[1] \"character\"\n\ntypeof(fx)\n\n[1] \"integer\"\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit is organizing a survey about his favorite fruit stand, and asks his friends what fruit they prefer: “Apple”, “Banana”, or “Cherry”. The options are stored in a character vector. Create this character vector in R and then convert it into a factor.\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vectors and Factors in R</span>"
    ]
  },
  {
    "objectID": "Lecture-4-R-and-Vectors.html#dealing-with-ordinal-data",
    "href": "Lecture-4-R-and-Vectors.html#dealing-with-ordinal-data",
    "title": "4  Vectors and Factors in R",
    "section": "4.7 Dealing with Ordinal Data",
    "text": "4.7 Dealing with Ordinal Data\nIf we remember from our previous lectures, categorical data can fall into two types: Nominal and Ordinal. Right now our factor() function is returning the values in a nominal form (meaning the factors have no specific ordering) and thus we cannot compare values.\n\nfx[1] &gt; fx[2]\n\nWarning in Ops.factor(fx[1], fx[2]) : '&gt;' not meaningful for factors\n\n\n[1] NA\n\n\nIf we want to create ordinal data in R then all we have to do is specify the ‘ordered’ argument to be TRUE. An example of this can be seen below, but note that the levels are in alphabetical order by default.\n\ny &lt;- sample(c(\"Small\", \"Medium\", \"Large\"), 7, replace=TRUE)\ny\n\n[1] \"Large\"  \"Large\"  \"Small\"  \"Medium\" \"Large\"  \"Small\"  \"Large\" \n\nfy &lt;- factor(y, ordered=TRUE)\nfy\n\n[1] Large  Large  Small  Medium Large  Small  Large \nLevels: Large &lt; Medium &lt; Small\n\n\nThis is obviously not what we want. When we go to a restaurant and order a side of fries, we expect the Large to be bigger than the Medium which is bigger than the Small. To have the levels end up in the correct order, we will want to use the ‘levels’ argument and pass it a vector of the correct ordering. When you do this, the spelling has to be the same (even the capitalization) for R to recognize it. Now that we have an ordered factor, we can compare values using logical operators.\n\nfy &lt;- factor(y, ordered=TRUE, levels=c(\"Small\", \"Medium\", \"Large\"))\nfy\n\n[1] Large  Large  Small  Medium Large  Small  Large \nLevels: Small &lt; Medium &lt; Large\n\nclass(fy)\n\n[1] \"ordered\" \"factor\" \n\nfy[1] &gt; fy[2]\n\n[1] FALSE\n\n\nAdditionally, we can always see the possible categories an element can have in the factor by using the levels() function. Finally, if we wish to change the levels then we can do so by assigning a new character vector to the current levels of factor. Be careful with this, as we do not want to pass in the order of the vector elements, rather we want to pass in the order of the levels.\n\nfy\n\n[1] Large  Large  Small  Medium Large  Small  Large \nLevels: Small &lt; Medium &lt; Large\n\nlevels(fy)\n\n[1] \"Small\"  \"Medium\" \"Large\" \n\nlevels(fy) &lt;- c(\"mini\", \"regular\", \"huge\")\nfy\n\n[1] huge    huge    mini    regular huge    mini    huge   \nLevels: mini &lt; regular &lt; huge\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit is helping organize a welcome event for new students. As part of the planning, he collects data on the class standings of students who RSVP’d. Help Emmit store this data as an ordered factor.\n\nstanding &lt;- sample(c(\"Freshman\", \"Sophomore\", \"Junior\", \"Senior\"), 10, replace=TRUE)\n\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vectors and Factors in R</span>"
    ]
  },
  {
    "objectID": "Lecture-4-R-and-Vectors.html#rstudio",
    "href": "Lecture-4-R-and-Vectors.html#rstudio",
    "title": "4  Vectors and Factors in R",
    "section": "4.8 RStudio",
    "text": "4.8 RStudio\nSo far, we have been using the R Console (RGui) to run code. While this is sufficient to run all of our R code, we are going to introduce a program called RStudio. This is the most commonly used IDE (Integrated Development Environment) for R which will allow us to be more organized and better for trouble-shooting our code. It is maintained by Posit and can be downloaded . Since you already have R installed, you will only need to download the RStudio Desktop. Once this is done it should look something like this:\n\n\n\n\n\nWe will run our code in the bottom left panel with the option to save our code in the top left panel using a script or text file (more to come on this in future lectures). In the top right panel we will be able to see the variables saved in our R environment along with a history of our code. In the bottom right panel we will be able to view plots, read documentation, and browse files on our computer.\n\n\nCreate variables in R to do the following:\n\nCreate a variable age and assign it your age as a double.\n\nCreate a variable student and assign it a logical value indicating if you are a student (TRUE/FALSE).\n\nCreate a variable favorite_food and assign it your favorite food as a character string.\n\nUse the typeof() function to check the type of each variable.\n\nCombine all three variables into a vector combined_vec using c() and check its type using class(). What do you notice about the elements?\n\nCreate a numeric vector scores with values: 82, 90, 75, 88, 95.\n\nCalculate the mean, median, and standard deviation of scores.\n\nCreate a logical vector indicating which scores are above 85.\n\nUse this logical vector to subset and display only scores above 85.\n\nMultiply all scores by 1.1 to simulate a 10% curve and display the new scores.\n\nCreate a character vector colors with values \"red\", \"blue\", \"green\", \"yellow\".\n\nCreate a logical vector likes_color of length 4, with TRUE for \"blue\" and \"green\" and FALSE otherwise.\n\nUse logical indexing to return only the colors you like.\n\nTry combining colors and likes_color into one vector. What happens to the types?\n\nCreate a vector temps with the values 72, 75, 78, 80, 77, 74.\n\nAccess the first, third, and last elements using indexing.\n\nUse a logical condition to find and display all temps greater than or equal to 77.\n\nReplace the second element with 76 and display the updated vector.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vectors and Factors in R</span>"
    ]
  },
  {
    "objectID": "Lecture-4-R-and-Vectors.html#data-types-in-r",
    "href": "Lecture-4-R-and-Vectors.html#data-types-in-r",
    "title": "4  Vectors and Factors in R",
    "section": "",
    "text": "Try it Out\n\n\n\nEmmit is working at his smoothie stand and tracking sales data. What is the type of each variable and what will he get if he sums up the protien_added variable?\n\nflavors &lt;- c(\"berry\", \"mango\", \"banana\")\nsales &lt;- c(12, 15, 9)\nprotein_added &lt;- c(TRUE, FALSE, TRUE)\nmistake &lt;- c(sales, \"error\")\n\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Vectors and Factors in R</span>"
    ]
  },
  {
    "objectID": "Lecture-5-More-R.html",
    "href": "Lecture-5-More-R.html",
    "title": "5  More R",
    "section": "",
    "text": "5.1 Creating a Sequence of Numbers\nSo far we have seen the basics of R, including ways to use R as a calculator as well as how to create variables and vectors. As a quick reminder, we can create a vector containing multiple elements by using our c() function (which stands for combine). After creating a vector we could then save it to a variable name by having the value point towards the name of our variable. To do this, we will use the assignment operator which looks like this: \\(&lt;\\)–. An example of this can be seen below:\nNow that we’ve covered the basics of R, including simple calculations, variables, and vectors, it’s time to dive a little deeper. In this section, we will explore more of R’s built-in functionality that makes data manipulation efficient and expressive. You’ll learn how to generate sequences, replicate values, name vector elements, and search using patterns. We’ll also explore special functions that help us handle data more effectively. These tools will become essential as we begin working with larger and more complex datasets.\nThere are additional ways we could make a vector as well. If we wanted all of our numbers in a sequence then we could use the seq() function to do this. With this function, we can specify what our starting value is and what we want the sequence to do. The function also allows us to pass an argument into it which specifies what value we should increment the sequence by. If we do not specify what we should increment by then it will automatically default to 1. We can also count down if we would like. Finally, it should be mentioned that most functions do not require us to write the argument name as long as we pass them in the correct order (but we should probably keep doing it until we are more comfortable).\nseq(from=1, to=10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nseq(from=1, to=10, by=2)\n\n[1] 1 3 5 7 9\n\nseq(7, 1)\n\n[1] 7 6 5 4 3 2 1\n\nseq(from=30, to=1, by=-4)\n\n[1] 30 26 22 18 14 10  6  2\n\nseq(-1, 2, by=0.3)\n\n [1] -1.0 -0.7 -0.4 -0.1  0.2  0.5  0.8  1.1  1.4  1.7  2.0\nIf we do not need to increment the sequence by a certain value then we could do something similar with a colon. This will create a sequence by just adding 1 to a value until it reaches the end number. An example of this can be seen below:\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n7:-2\n\n [1]  7  6  5  4  3  2  1  0 -1 -2\n\n0.25:7.75 # Notice how it does not go past the ending value\n\n[1] 0.25 1.25 2.25 3.25 4.25 5.25 6.25 7.25",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>More R</span>"
    ]
  },
  {
    "objectID": "Lecture-5-More-R.html#replicating-values",
    "href": "Lecture-5-More-R.html#replicating-values",
    "title": "5  More R",
    "section": "5.2 Replicating Values",
    "text": "5.2 Replicating Values\nWe can replicate values (of any type) using the rep() function. This will allow us to pass a vector into the function and have it be replicated a certain number of times (and the number of times could also be a vector!). If we pass a vector in for the number of times then it will match it element by element and replicate it the specified number of times before going on to the next element.\n\nrep(2, times=6)\n\n[1] 2 2 2 2 2 2\n\nrep(\"abc\", times=3)\n\n[1] \"abc\" \"abc\" \"abc\"\n\nrep(1:4, times=4:1) # 1st element 4 times, 2nd element 3 times, etc.\n\n [1] 1 1 1 1 2 2 2 3 3 4\n\nrep(c(7,2,1), times=c(1,4,8))\n\n [1] 7 2 2 2 2 1 1 1 1 1 1 1 1\n\n\nThe function allows for other arguments as well, such as the length of the outputted sequence and if all of the elements should be replicated a certain amount of times. The ‘each’ argument will replicate each element a certain number of times while the ‘length.out’ argument will keep repeating a sequence until it is of a certain length.\n\nrep(c(7,2,1), times=2)\n\n[1] 7 2 1 7 2 1\n\nrep(c(7,2,1), each=2)\n\n[1] 7 7 2 2 1 1\n\nrep(c(7,2,1), length.out = 8)\n\n[1] 7 2 1 7 2 1 7 2\n\nrep(c(7,2,1), each=3, length.out=10)\n\n [1] 7 7 7 2 2 2 1 1 1 7\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit surveys his friends regarding their favorite fruit, and determines that 7 of them like apples, 4 like bananas, 3 like oranges, and 1 likes pineapple. How can he display this information using the rep() function?\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>More R</span>"
    ]
  },
  {
    "objectID": "Lecture-5-More-R.html#creating-a-vector-of-letters",
    "href": "Lecture-5-More-R.html#creating-a-vector-of-letters",
    "title": "5  More R",
    "section": "5.3 Creating a Vector of Letters",
    "text": "5.3 Creating a Vector of Letters\nAs a quick reminder (since it is very important), R starts indexing at 1. This means that the first element in a vector is in the ‘1’ index. Other languages, like Python, start counting at 0 but we will start counting at 1 in R. In R there is a vector called ‘letters’ that contains all of the lower-case letters. If we want to find out what the 4th letter is then we can use our “index-selection” brackets. We can also pass a vector into the index selection brackets as well, which includes sequences and replicated vectors (as long as they are numeric). There is also a vector in R called `LETTERS’ which acts the same way but contains all capitalized letters.\n\nx &lt;- letters # Saving the vector to 'x' for simplicity\nx\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\nx[c(13, 15, 21, 14, 20)]\n\n[1] \"m\" \"o\" \"u\" \"n\" \"t\"\n\nx[17:22]\n\n[1] \"q\" \"r\" \"s\" \"t\" \"u\" \"v\"\n\nLETTERS[c(8, 5, 12, 12, 15)]\n\n[1] \"H\" \"E\" \"L\" \"L\" \"O\"\n\n\nIf we ever wish to have all of the values displayed except for certain ones then we can put a negative in front of the value/vector and it will display everything except those values. This is helpful when it is easier to exclude certain indices instead of having to specify all of the desired indices.\n\nx[seq(1,26,by=2)] # Every other letter\n\n [1] \"a\" \"c\" \"e\" \"g\" \"i\" \"k\" \"m\" \"o\" \"q\" \"s\" \"u\" \"w\" \"y\"\n\nx[-seq(1,26,by=2)] # Everything but these indices\n\n [1] \"b\" \"d\" \"f\" \"h\" \"j\" \"l\" \"n\" \"p\" \"r\" \"t\" \"v\" \"x\" \"z\"\n\ny &lt;- 1:10\ny\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\ny[c(1,5,8)]\n\n[1] 1 5 8\n\ny[-c(1,5,8)]\n\n[1]  2  3  4  6  7  9 10\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit is making a display for his smoothie stand and wants it to say “EMMIT smoothies”. Help him do this in R.\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>More R</span>"
    ]
  },
  {
    "objectID": "Lecture-5-More-R.html#named-vectors",
    "href": "Lecture-5-More-R.html#named-vectors",
    "title": "5  More R",
    "section": "5.4 Named Vectors",
    "text": "5.4 Named Vectors\nSince we have been discussing vectors and their elements, we should go ahead and mention that we can name the individual elements as well (this might make it easier for us to refer back to a specific element as we might not remember which index it is). There are a few different ways we can do this, the first is by naming them when we create the vector itself. To do this we will just put the name of the element to the left of the element with an equals sign in between. It may look something like this:\n\nx &lt;- c(M=\"Monday\", W=\"Wednesday\", F=\"Friday\")\nx\n\n          M           W           F \n   \"Monday\" \"Wednesday\"    \"Friday\" \n\nnames(x)\n\n[1] \"M\" \"W\" \"F\"\n\n\nAnother way that might be beneficial is to name them after the vector has been created using the names() function. We will reference the names function with the vector inside and we will assign a character vector to it. This will update the names of the vector elements as whatever we passed into it. An example of this can also be seen below:\n\nx &lt;- c(\"Monday\", \"Wednesday\", \"Friday\")\nnames(x)\n\nNULL\n\nnames(x) &lt;- c(\"M\", \"W\", \"F\")\nx\n\n          M           W           F \n   \"Monday\" \"Wednesday\"    \"Friday\" \n\nnames(x)\n\n[1] \"M\" \"W\" \"F\"\n\n\nBecause the elements are named, we can pass the names into our index-selection brackets and R will output the element associated with that particular name. We will also still be able to access them with the index value as well.\n\nx[\"M\"]\n\n       M \n\"Monday\" \n\nx[c(\"M\", \"F\")]\n\n       M        F \n\"Monday\" \"Friday\" \n\nx[c(1,3)]\n\n       M        F \n\"Monday\" \"Friday\" \n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit has been operating the smoothie stand for a few weeks now and wants to calculate how many smoothies of each flavor he has sold. Help him create a named vector if he has sold 42 Strawberry, 37 Manhgo, and 28 Pineapple smoothies.\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>More R</span>"
    ]
  },
  {
    "objectID": "Lecture-5-More-R.html#index-selection-using-grep",
    "href": "Lecture-5-More-R.html#index-selection-using-grep",
    "title": "5  More R",
    "section": "5.5 Index Selection using GREP",
    "text": "5.5 Index Selection using GREP\nOne very powerful tool in R that allows us to search a string for a specific pattern is the grep() function. This stands for Global/Regular Expression/Print and is important to us as it will allow us to identify all of the elements containing a specific pattern. To see this function in action we will utilize the “euro” vector which is a named vector available to us in R.\n\neuro\n\n        ATS         BEF         DEM         ESP         FIM         FRF \n  13.760300   40.339900    1.955830  166.386000    5.945730    6.559570 \n        IEP         ITL         LUF         NLG         PTE \n   0.787564 1936.270000   40.339900    2.203710  200.482000 \n\n\nBefore we jump into using the function though, we will want to discuss some of the syntax that the grep() uses. The first is that it expects us to pass a pattern into it using quotation marks. If we type a \\(\\wedge\\) at the beginning of the pattern then it will search for strings starting with the pattern. If we type a $ at the end of the pattern then it will search for strings ending with the pattern. A single period will stand for any character, and characters in brackets will mean “any of these characters”. After we specify the pattern we will need to also specify where we are looking for the pattern, and in our case, it will be the names of the euro vector. The output for this function will be the indices of the elements which contain the specified pattern.\n\nnames(euro)\n\n [1] \"ATS\" \"BEF\" \"DEM\" \"ESP\" \"FIM\" \"FRF\" \"IEP\" \"ITL\" \"LUF\" \"NLG\" \"PTE\"\n\ngrep(\"E\", names(euro)) # Indices of elements containing an E anywhere\n\n[1]  2  3  4  7 11\n\neuro[grep(\"E\", names(euro))] # Names containing an E anywhere\n\n       BEF        DEM        ESP        IEP        PTE \n 40.339900   1.955830 166.386000   0.787564 200.482000 \n\ngrep(\"^I\", names(euro)) # Indices of elements starting with I\n\n[1] 7 8\n\neuro[grep(\"^I\", names(euro))] # Names starting with I\n\n        IEP         ITL \n   0.787564 1936.270000 \n\ngrep(\"F$\", names(euro)) # Indices of elements ending with F\n\n[1] 2 6 9\n\neuro[grep(\"F$\", names(euro))] # Names ending with F\n\n     BEF      FRF      LUF \n40.33990  6.55957 40.33990 \n\ngrep(\".E.\", names(euro)) # Indices of elements containing _E_\n\n[1] 2 3 7\n\neuro[grep(\".E.\", names(euro))] # Names containing with _E_\n\n      BEF       DEM       IEP \n40.339900  1.955830  0.787564 \n\ngrep(\".[EI].\", names(euro)) # Indices of elements containing _E_ or _I_\n\n[1] 2 3 5 7\n\neuro[grep(\".[EI].\", names(euro))] # Names containing _E_ or _I_\n\n      BEF       DEM       FIM       IEP \n40.339900  1.955830  5.945730  0.787564 \n\n\nWhile this function may seem a little complicated at first, it is a very powerful tool that will allow us to filter out observations that meet certain criteria. One example might be searching a vector for all observations with the last name “Smith” or for people whose first name starts with the letters “Ca”.\n\n\n\n\n\n\nTry it Out\n\n\n\nThe smoothie stand has the following flavors. How can he display the flavors that start with Berry, end with Crush, or have two consecutive vowels.\n\nflavors &lt;- c(\"Mango Madness\", \"Berry Blast\", \"Peach Punch\", \"Pineapple Punch\", \n             \"Acai Antioxidant\", \"Tropical Berry Twist\", \"Citrus Crush\", \n             \"Berry Goddess\", \"Chocolate Crush\", \"Vanilla Velvet\")\n\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>More R</span>"
    ]
  },
  {
    "objectID": "Lecture-5-More-R.html#logical-vectors-and-index-selection",
    "href": "Lecture-5-More-R.html#logical-vectors-and-index-selection",
    "title": "5  More R",
    "section": "5.6 Logical Vectors and Index Selection",
    "text": "5.6 Logical Vectors and Index Selection\nWe briefly saw it in the previous lecture, but it is important for us to practice accessing vector elements using logical vectors. If any logical operator (\\(&lt;,&lt;=, &gt;, &gt;=, ==, !=\\)) is used to compare vectors, the resulting output will be a logical vector. This will always be the case! It is good practice to think about what the outputted results will be before we even run the code instead of just “hoping for the best”.\nWe can access the vector elements using logical vectors in two ways; explicitly and implicitly. Doing it explicitly would mean we save the logical vector to a new variable and then use the new variable in our index-selection brackets while doing it implicitly would mean we place the logical comparison into the index-selection brackets directly. I prefer the implicit method as we do not have to re-run the code if the original vector changes. Both examples can be seen below:\n\nx &lt;- c(4,8,2,6,7,6,3,8,6)\ny &lt;- x &gt; 6\n\ny\n\n[1] FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE\n\nx[y] # Explicit creation\n\n[1] 8 7 8\n\nx[x&gt;6] # Implicit creation\n\n[1] 8 7 8\n\nx\n\n[1] 4 8 2 6 7 6 3 8 6\n\nx &gt;= 7\n\n[1] FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE\n\nlength(x &gt;= 7) # Length of the vector is 11 elements\n\n[1] 9\n\nsum(x &gt;= 7) # Adding the logical vector: TRUE = 1, FALSE = 0\n\n[1] 3\n\nx[x &gt;= 7] # Displaying just the values whose index is TRUE\n\n[1] 8 7 8\n\n\nWe can expand our capabilities with logical operators and introduce a few new operators which will allow us to evaluate multiple conditions at the same time. These include & (which represents and), \\(\\vert\\) (which represents or and is the pipe symbol above the enter key), and ! (which represents not). The and will require both conditions to be true for the output to be true, the or only requires one condition to be true for the output to be true, and the not “flips” the final output to be the opposite.\n\nx &lt;- 1:11\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10 11\n\n(x &gt;5) & (x &lt; 10) # Is the element greater than 5 and less than 10\n\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE\n\nx[(x &gt;5) & (x &lt; 10)] # Displaying the elements that are TRUE\n\n[1] 6 7 8 9\n\n(x &lt; 5) | (x &gt; 9) # Is the elements less than 5 or greater than 9\n\n [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE\n\nx[(x &lt; 5) | (x &gt; 9)] # Displaying the elements that are TRUE\n\n[1]  1  2  3  4 10 11\n\n!(x &gt; 6) # Is the element not greater than 6\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n\nx[!(x &gt; 6)] # Displaying the elements that are TRUE\n\n[1] 1 2 3 4 5 6\n\n\nIt is important to play around with the logical operators to get comfortable with filtering out elements that meet certain criteria. If you have multiple conditions you may need to use parenthesis to have it do what you wish, as it does the and operation before the or operation.\n\nx[(x &gt; 5 | x &lt; 3) & x &lt; 4] \n\n[1] 1 2\n\nx[x &gt; 5 | x &lt; 3 & x &lt; 4]\n\n[1]  1  2  6  7  8  9 10 11\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit has calculated the number of he has sold for each of the past 10 days. How many days did he sell less than 7.5 smoothies? How mant days did he sell either less than 5 or greater than 15 smoothies?\n\nsales &lt;- c(12, 5, 9, 15, 7, 3, 10, 20, 7, 6)\n\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>More R</span>"
    ]
  },
  {
    "objectID": "Lecture-5-More-R.html#sample-function",
    "href": "Lecture-5-More-R.html#sample-function",
    "title": "5  More R",
    "section": "5.7 Sample Function",
    "text": "5.7 Sample Function\nThere are a few special functions in R that we should discuss that will be used throughout the course. The first is the sample() function which will allow us to randomly sample values from a vector that we pass into it. We will be able to choose how many values we want to be outputted and whether we want to allow the repetition of the values (this will need to be true if we want to output more values than we passed in). The exact values that are returned are not predictable as they rely on a random number generator behind the scenes. If we wish to get the same values over and over again then we need to use the set.seed() function to achieve this goal. An example of using the sample() function can be seen below:\n\nsample(1:10, 5, replace=TRUE)\n\n[1] 2 3 7 9 9\n\nsample(1:10, 5, replace=TRUE)\n\n[1] 2 7 9 1 8\n\nsample(1:10, 5, replace=TRUE)\n\n[1]  8  6 10  1  5\n\n\n\nsample(1:10, 15, replace=FALSE)\n\nError in sample.int(length(x), size, replace, prob) : cannot take a sample larger than the population when 'replace = FALSE'\n\nsample(1:10, 15, replace=TRUE)\n\n [1] 5 9 6 2 7 3 7 9 4 6 6 5 3 6 1\n\nset.seed(123)\nsample(c(\"A\", \"B\", \"C\"), 10, replace=TRUE)\n\n [1] \"C\" \"C\" \"C\" \"B\" \"C\" \"B\" \"B\" \"B\" \"C\" \"A\"\n\nsample(c(\"A\", \"B\", \"C\"), 10, replace=TRUE)\n\n [1] \"B\" \"B\" \"A\" \"B\" \"C\" \"A\" \"C\" \"C\" \"A\" \"A\"\n\nset.seed(123) # This will result in the same thing as above\nsample(c(\"A\", \"B\", \"C\"), 10, replace=TRUE)\n\n [1] \"C\" \"C\" \"C\" \"B\" \"C\" \"B\" \"B\" \"B\" \"C\" \"A\"\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit wants to run a promotion where he randomly selects smoothie flavors to feature each day. Help him write R code which randomly picks 3 flavors to promote each day.\n\nflavors &lt;- c(\"Mango Madness\", \"Berry Blast\", \"Peach Punch\", \"Pineapple Punch\", \n             \"Acai Antioxidant\", \"Tropical Berry Twist\", \"Citrus Crush\", \n             \"Berry Goddess\", \"Chocolate Crush\", \"Vanilla Velvet\")\n\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>More R</span>"
    ]
  },
  {
    "objectID": "Lecture-5-More-R.html#special-functions-in-r",
    "href": "Lecture-5-More-R.html#special-functions-in-r",
    "title": "5  More R",
    "section": "5.8 Special Functions in R",
    "text": "5.8 Special Functions in R\nAnother special function that may come in handy is the which() function. What this will do is tell us the index values of the elements which meet certain criteria. Note in the sample below that it is telling us the 6th, 12th, 13th, and 20th elements in the vector are greater than 40 (it is not telling us the values greater than 40, just the indices of the elements):\n\nx &lt;- sample(1:50, 20, replace=TRUE)\nx\n\n [1]  4 39  1 34 23 43 14 18 33 21 21 42 46 10  7  9 15 21 37 41\n\nwhich(x &gt; 40) # Indices with values greater than 40\n\n[1]  6 12 13 20\n\nx[which(x &gt; 40)] # Values greater than 40\n\n[1] 43 42 46 41\n\n\nOther functions which may be of use to us are the duplicated() function and the unique() function. The first function, duplicated(), will return a logical vector with TRUE after the first occurrence of duplicated values. So, the second time (and additional times) a number appears it will output TRUE. The unique() function will return just the unique values of the vector, meaning it will remove all of the duplicated values.\n\nx\n\n [1]  4 39  1 34 23 43 14 18 33 21 21 42 46 10  7  9 15 21 37 41\n\nduplicated(x)\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE\n\nunique(x)\n\n [1]  4 39  1 34 23 43 14 18 33 21 42 46 10  7  9 15 37 41\n\n\nTwo other functions that will result in a single logical output are the any() and the all() function. These will do what their names sound like, that is they will see if any values in the vector meet certain criteria and if all values in the vector meet certain criteria.\n\nx\n\n [1]  4 39  1 34 23 43 14 18 33 21 21 42 46 10  7  9 15 21 37 41\n\nany(x &gt; 45)\n\n[1] TRUE\n\nany(x &lt; 10)\n\n[1] TRUE\n\nall(x &lt;= 45)\n\n[1] FALSE\n\nall(x &lt; 10)\n\n[1] FALSE\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit has calculated the number of he has sold for each of the past 10 days. Using the functions in this section determine which days had sales greater than or equal to 15 and if the sales on a day matched a previous day’s total.\n\nsales &lt;- c(12, 5, 9, 15, 7, 3, 10, 20, 7, 6)\n\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>More R</span>"
    ]
  },
  {
    "objectID": "Lecture-5-More-R.html#getting-help",
    "href": "Lecture-5-More-R.html#getting-help",
    "title": "5  More R",
    "section": "5.9 Getting Help",
    "text": "5.9 Getting Help\nWhile I have thrown a lot of information at you in this lecture, know that R provides help and resources for all functions. So, if we are ever confused about a specific function or do not know what parameters we can pass into the function, then we can always use a question mark to search for the documentation. That is if we are curious about the mean() function then we can type ?mean.\nUsing two question marks will search the database for the phrase if we are unsure what the function is called. For instance, we could type ?? “Standard Deviation” if we are unsure of the name of the function. Do not worry if you cannot remember everything, as you use it more and more it will become second nature. Even I have to regularly look at the R Documentation to see examples and to see what the options are for each function.\n\n\nCreate sequences in R to do the following:\n\nCreate a sequence of numbers from 1 to 20 incrementing by 3 using the seq() function.\n\nUsing the rep() function, create a vector that contains the elements 5, 10, and 15, where 5 is repeated 3 times, 10 is repeated 2 times, and 15 is repeated 4 times.\n\nUsing the built-in letters vector, extract and display the letters at the 3rd, 6th, 9th, and 12th positions.\nName the vector c(50, 100, 200) with the names \"Small\", \"Medium\", and \"Large\", then access the element named \"Medium\".\n\nCreate a vector states with values: “California”, “Colorado”, “Connecticut”, “Delaware”, “Florida”, “Georgia”, “Hawaii”, “Idaho”, “Illinois”, “Indiana”\n\nUse grep() to find all states that start with the letter \"C\" and display those states.\nUse grep() to find all states that end with the letter \"a\" and display those states.\nUse grep() to find all states that contain the letters \"_n\" (with _ being any letter) or \"or\".\nUse logical operators to display all states that contain either \"Florida\" or \"Georgia\".\n\nUse the sample() function to randomly select 7 values from the numbers 1 through 20 without replacement.\nCreate a vector temperature with the values 72, 75, 78, 80, 77, 74, 91, 84, 85, 93, 80.\n\nUse the which() function to find the indices where the daily temperature is equal to 80\nUse the duplicated() function to identify which day’s temperatures are duplicates.\nUse the unique() function to get the distinct daily temperature values.\nUse the any() function to check if any days have temperatures below 80.\nUse the all() function to check if all days have temperatures 80 or less.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>More R</span>"
    ]
  },
  {
    "objectID": "Lecture-5-More-R.html#creating-a-sequence-of-numbers",
    "href": "Lecture-5-More-R.html#creating-a-sequence-of-numbers",
    "title": "5  More R",
    "section": "",
    "text": "Try it Out\n\n\n\nEmmit is interested in displaying all of the possible GPA values rounded to 2 decimal places. How can he do this is the GPA must be between 0 and 4.0?\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>More R</span>"
    ]
  },
  {
    "objectID": "Lecture-7-Dataframes-in-R.html#creating-dataframes",
    "href": "Lecture-7-Dataframes-in-R.html#creating-dataframes",
    "title": "7  Dataframes in R",
    "section": "",
    "text": "Try it Out\n\n\n\nEmmit is organizing a small conference and wants to keep track of attendees. Make a dataframe which looks exactly like the following list:\n\n\n    name age      role registered\n1   Adam  30  attendee       TRUE\n2   Brad  49   speaker       TRUE\n3 Claire  32 organizer       TRUE\n4 Donald  28 attendeee      FALSE\n5 Elaine  27  attendee      FALSE\n6  Fiona  33 organizer       TRUE\n\n\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Dataframes in R</span>"
    ]
  },
  {
    "objectID": "Lecture-8-Exploratory-Data-Analysis.html",
    "href": "Lecture-8-Exploratory-Data-Analysis.html",
    "title": "8  Exploratory Data Analysis",
    "section": "",
    "text": "8.1 The Basics of EDA\nThe Data Science Life-cycle consists of procuring the data, tidying the data to make it workable, and then repeatedly transforming, visualizing, and modeling the data until our results are finalized to how we would like them. After we are happy with the results, we then have to communicate the information to our respective audience. For this class, we will focus on transforming the data, visualizing the data, and communicating the data. Future courses will emphasize “tidying” large datasets and building models to better describe data.\nWhenever we start working with a new dataset for the first time, we will want to carry out Exploratory Data Analysis (EDA) to understand what we are looking at. Some questions we may ask ourselves are: What does the data represent, What does the data look like, and Are there any problems (missing or unusual) with the data values? These questions will help us complete the first goal of EDA. We should note that these goals were designed/created by Professor Portier and they will not be found online or in other literature. The first goal, which will help us understand what our data is, can be seen below:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Data Analysis</span>"
    ]
  },
  {
    "objectID": "Lecture-8-Exploratory-Data-Analysis.html#the-basics-of-eda",
    "href": "Lecture-8-Exploratory-Data-Analysis.html#the-basics-of-eda",
    "title": "8  Exploratory Data Analysis",
    "section": "",
    "text": "Goal One: Getting to know the Data\n\nStep One: What is the data?\nStep Two: Logical vs Physical\nStep Three: Data Conditions\nStep Four: Data Preparation\nStep Five: Initial Summary\nStep Six: Data Visualization",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Data Analysis</span>"
    ]
  },
  {
    "objectID": "Lecture-8-Exploratory-Data-Analysis.html#step-1-what-is-the-data",
    "href": "Lecture-8-Exploratory-Data-Analysis.html#step-1-what-is-the-data",
    "title": "8  Exploratory Data Analysis",
    "section": "8.2 Step 1: What is the Data?}",
    "text": "8.2 Step 1: What is the Data?}\nWe can attempt to answer Step One: What is the Data, by looking at the logical structure (metadata) of the data. Normally datasets come with documentation that tells us how the data was captured, what the attributes are that are being measured, and the data types and units present in the dataset. This will be helpful to look at as a first glance of the dataset to understand what we are working with. There are a few datasets that we will regularly use in R, one is the “datasets” library (built into R) and the other in the “openintro” library. To access a library for the first time we need to install the package using the install.packages() function. We will only need to do this once. After we have the package installed, we will need to use the library() function every time we start a new session (or RMarkdown file) to access the functions/datasets inside the package. To learn more about the packages we can use the help() function.\n\nhelp(package = \"datasets\") # Datasets built-in to R\ninstall.packages(\"openintro\") # Installing a package- only do this once\nlibrary(openintro) # Loading library into environment- do this every session\nhelp(package = \"openintro\") # Datasets in openintro library\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit is taking an Introductory Data Science course and has learned about a package created specifically for students in his course. Help Emmit install, load, and view the documentation for the “MSMU” package.\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Data Analysis</span>"
    ]
  },
  {
    "objectID": "Lecture-8-Exploratory-Data-Analysis.html#step-2-logical-vs.-physical",
    "href": "Lecture-8-Exploratory-Data-Analysis.html#step-2-logical-vs.-physical",
    "title": "8  Exploratory Data Analysis",
    "section": "8.3 Step 2: Logical vs. Physical",
    "text": "8.3 Step 2: Logical vs. Physical\nIn Step Two: Logical vs Physical, we will want to make sure the documentation and the actual data match up. We will want to check that the number of variables and observations is the same in both places. To do this we can use the help() function to read the documentation and the str() function to look at the actual structure of the dataframe. Comparing both is an important step, especially when we start working with large “real-world” datasets. If the documentation and the data do not match up then we should be wary about working with the dataset as it might be missing vital information.\n\nhelp(mtcars) # Reading the documentation\nstr(mtcars) # Looking at the dataset structure\n\n\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nHelp Emmit look at the documentation for the “income_data” dataset in the “MSMU” library and verify that it matches the data avaliable in the package.\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Data Analysis</span>"
    ]
  },
  {
    "objectID": "Lecture-8-Exploratory-Data-Analysis.html#special-values-in-r",
    "href": "Lecture-8-Exploratory-Data-Analysis.html#special-values-in-r",
    "title": "8  Exploratory Data Analysis",
    "section": "8.4 Special Values in R}",
    "text": "8.4 Special Values in R}\nAfter we have confirmed that the documentation and the data align with each other, we will want to investigate if there is anything unusual with the data. For instance, are there any missing or special values? A few special values that we might encounter are missing data (indicated as **NA), non-numeric data (indicated as NaN* which stands for Not a Number), and extreme values that are beyond the computer’s limits (indicated as \\(\\pm\\) Inf). Below we can see a few missing values when we look at the structure of the “airquality” dataset, as well as other ways in which we might encounter special values. Notice how in R the value \\(-42/0\\) is \\(-\\infty\\) but in math we would consider it Undefined.\n\nstr(airquality)\n\n'data.frame':   153 obs. of  6 variables:\n $ Ozone  : int  41 36 12 18 NA 28 23 19 8 NA ...\n $ Solar.R: int  190 118 149 313 NA NA 299 99 19 194 ...\n $ Wind   : num  7.4 8 12.6 11.5 14.3 14.9 8.6 13.8 20.1 8.6 ...\n $ Temp   : int  67 72 74 62 56 66 65 59 61 69 ...\n $ Month  : int  5 5 5 5 5 5 5 5 5 5 ...\n $ Day    : int  1 2 3 4 5 6 7 8 9 10 ...\n\nc(2^8392, -42/0, 0/0)\n\n[1]  Inf -Inf  NaN",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Data Analysis</span>"
    ]
  },
  {
    "objectID": "Lecture-8-Exploratory-Data-Analysis.html#step-3-data-conditions",
    "href": "Lecture-8-Exploratory-Data-Analysis.html#step-3-data-conditions",
    "title": "8  Exploratory Data Analysis",
    "section": "8.5 Step 3: Data Conditions",
    "text": "8.5 Step 3: Data Conditions\nFor large datasets, we will not want to scan the whole dataset to see if missing values are present though. Thankfully, we can determine if a dataset or specific column has missing values present by using the is.na() function. This will return a logical vector of TRUE and FALSE depending on if the individual elements are NA. We can then sum up the logical vector to determine how many missing values are present.\n\nsum(is.na(airquality$Ozone))\n\n[1] 37\n\nsum(is.na(airquality$Solar.R))\n\n[1] 7\n\nsum(is.na(airquality$Wind))\n\n[1] 0\n\n\nIf we want to investigate where the missing values occur we could use the which() function to identify the elements that are missing.\n\nhead(airquality$Ozone, 10)\n\n [1] 41 36 12 18 NA 28 23 19  8 NA\n\nis.na(head(airquality$Ozone, 10))\n\n [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE\n\nwhich(is.na(head(airquality$Ozone, 10)))\n\n[1]  5 10\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nLooking at the “income_data” dataset in the “MSMU” library, help Emmit determine if there are any missing values present and where they occur.\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX\n\n\n\nIt may also be a good idea to print out the unique values to see if there are any missing or unusual values. To do this, we can use the unique() function as well as the sort() function. One other thing we might look for the an outlier value. For instance, 999 might indicate a missing value if all other values are around 20. Another thing we will note is that some functions will not work properly if missing values exist. If this is the case then we might need to specify the argument na.rm=TRUE to remove the missing values before running the function.\n\nsort(unique(airquality$Ozone), na.last=TRUE)\n\n [1]   1   4   6   7   8   9  10  11  12  13  14  16  18  19  20  21  22  23  24\n[20]  27  28  29  30  31  32  34  35  36  37  39  40  41  44  45  46  47  48  49\n[39]  50  52  59  61  63  64  65  66  71  73  76  77  78  79  80  82  84  85  89\n[58]  91  96  97 108 110 115 118 122 135 168  NA\n\nrange(airquality$Ozone)\n\n[1] NA NA\n\nrange(airquality$Ozone, na.rm=TRUE)\n\n[1]   1 168\n\nmean(airquality$Ozone)\n\n[1] NA\n\nmean(airquality$Ozone, na.rm=TRUE)\n\n[1] 42.12931\n\n\nWe can see how many complete observations we have using the complete.cases() function. This will return TRUE if all of the observations in a row are present and FALSE if a missing value is detected. This will be beneficial so we can see if all of the missing values are in a few observations or if they are spread throughout the dataset. In addition to this, we could calculate the number of complete rows as well as how many observations have missing values by using the sum() function. If we are interested in the proportion of observations that are complete then we can use the mean() function. This will calculate the mean of the TRUEs (1) and FALSEs (0) and return the proportion of TRUEs that we have.\n\nhead(airquality)\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\n\nhead(complete.cases(airquality))\n\n[1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE\n\nsum(complete.cases(airquality))\n\n[1] 111\n\nnrow(airquality) - sum(complete.cases(airquality))\n\n[1] 42\n\nsum(!complete.cases(airquality))\n\n[1] 42\n\nmean(complete.cases(airquality))\n\n[1] 0.7254902\n\nsum(complete.cases(airquality)) / nrow(airquality)\n\n[1] 0.7254902\n\n\nFinally, the last thing we may want to do in this step is to display all of the complete cases so that no missing values are present. To do this, we can pass the logical vector into our index-selection brackets. In the example below, notice how the 5th and 6th observation containing NA are no longer present:\n\nhead(airquality[complete.cases(airquality),])\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n7    23     299  8.6   65     5   7\n8    19      99 13.8   59     5   8\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nEmmit thinks that there are might be some unusual values present in the “income_data” dataset. Help him determine which values are unusual. Also help him calculate the mean number of years until retirement.\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Data Analysis</span>"
    ]
  },
  {
    "objectID": "Lecture-8-Exploratory-Data-Analysis.html#step-4-data-preparation",
    "href": "Lecture-8-Exploratory-Data-Analysis.html#step-4-data-preparation",
    "title": "8  Exploratory Data Analysis",
    "section": "8.6 Step 4: Data Preparation",
    "text": "8.6 Step 4: Data Preparation\nIn Step Four: Data Preparation, we will begin to alter the dataset to better represent certain columns. For instance, does one of our columns need to be changed from quantitative to categorical? We might also be interested in adding new columns based on the data or just generally cleaning it up to help us gain information from the dataset. One thing we might do is replace implicit missing value if, after talking to an expert they inform us the value is not correct or missing. For instance, if we talked to an expert and they said that the Ozone should not be 168 but should be a missing value instead then we can make that change.\n\nairquality$Ozone[airquality$Ozone == 168] &lt;- NA\nsort(unique(airquality$Ozone), na.last = TRUE)\n\n [1]   1   4   6   7   8   9  10  11  12  13  14  16  18  19  20  21  22  23  24\n[20]  27  28  29  30  31  32  34  35  36  37  39  40  41  44  45  46  47  48  49\n[39]  50  52  59  61  63  64  65  66  71  73  76  77  78  79  80  82  84  85  89\n[58]  91  96  97 108 110 115 118 122 135  NA\n\n\nWe will very rarely make changes to missing values in this course. Instead, we will most likely just filter them out from our calculations using the argument na.rm=TRUE. In Data 210 we will learn different options of how to replace them.\nIf we want to convert a variable to a different type then we can using the different data type’s function in R. Most of these will be of the form as.type() where “type” is replaced by the data type we are aiming for. So, if we want to convert a vector to numeric then we would use as.numeric(). If we wanted a character or logical vector instead we would say as.character() or as.logical(). For converting vector to a factor we could use factor().\nTo see an example of this we will look at the “beaver2” dataset, specifically at the “activ” variable. Looking at the documentation it seems “activ” is an indicator variable (either 0 or 1) which may be better suited to be a factor instead of an integer. So, we will go through the process of converting the vector into a factor. When we do this though, we do not want to change the column in R, rather we will create a new column to store the changed value. This way if we make a mistake the original data will still be present. So, to re-iterate… don’t overwrite your column!!! If we do happen to over-write a dataset in R then we can get the original dataset back by using the command data(“name of dataset”) and it will reload the original into your environment.\n\nstr(beaver2)\n\n'data.frame':   100 obs. of  4 variables:\n $ day  : num  307 307 307 307 307 307 307 307 307 307 ...\n $ time : num  930 940 950 1000 1010 1020 1030 1040 1050 1100 ...\n $ temp : num  36.6 36.7 36.9 37.1 37.2 ...\n $ activ: num  0 0 0 0 0 0 0 0 0 0 ...\n\nunique(beaver2$activ)\n\n[1] 0 1\n\nbeaver2$activ_f &lt;- factor(beaver2$activ)\nlevels(beaver2$activ_f) &lt;- c(\"No\", \"Yes\")\nstr(beaver2)\n\n'data.frame':   100 obs. of  5 variables:\n $ day    : num  307 307 307 307 307 307 307 307 307 307 ...\n $ time   : num  930 940 950 1000 1010 1020 1030 1040 1050 1100 ...\n $ temp   : num  36.6 36.7 36.9 37.1 37.2 ...\n $ activ  : num  0 0 0 0 0 0 0 0 0 0 ...\n $ activ_f: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nYou and Emmit noticed that unusual values were present in the “Ages” and the “Salary” column. Change the unusual values to NA so that they are properly coded.\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX\n\n\n\nSometimes it is helpful to convert a quantitative variable into a categorical variable by placing the data into different categories. To do this, we will “cut” the data into ranges and assign each value a category. An example of this can be seen below using the cut() function.\n\nrange(airquality$Ozone, na.rm=TRUE)\n\n[1]   1 135\n\ncut(airquality$Ozone, breaks=seq(0,150,by=25))\n\n  [1] (25,50]   (25,50]   (0,25]    (0,25]    &lt;NA&gt;      (25,50]   (0,25]   \n  [8] (0,25]    (0,25]    &lt;NA&gt;      (0,25]    (0,25]    (0,25]    (0,25]   \n [15] (0,25]    (0,25]    (25,50]   (0,25]    (25,50]   (0,25]    (0,25]   \n [22] (0,25]    (0,25]    (25,50]   &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;      (0,25]   \n [29] (25,50]   (100,125] (25,50]   &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;     \n [36] &lt;NA&gt;      &lt;NA&gt;      (25,50]   &lt;NA&gt;      (50,75]   (25,50]   &lt;NA&gt;     \n [43] &lt;NA&gt;      (0,25]    &lt;NA&gt;      &lt;NA&gt;      (0,25]    (25,50]   (0,25]   \n [50] (0,25]    (0,25]    &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;     \n [57] &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;      (125,150] (25,50]  \n [64] (25,50]   &lt;NA&gt;      (50,75]   (25,50]   (75,100]  (75,100]  (75,100] \n [71] (75,100]  &lt;NA&gt;      (0,25]    (25,50]   &lt;NA&gt;      (0,25]    (25,50]  \n [78] (25,50]   (50,75]   (75,100]  (50,75]   (0,25]    &lt;NA&gt;      &lt;NA&gt;     \n [85] (75,100]  (100,125] (0,25]    (50,75]   (75,100]  (25,50]   (50,75]  \n [92] (50,75]   (25,50]   (0,25]    (0,25]    (75,100]  (25,50]   (50,75]  \n [99] (100,125] (75,100]  (100,125] &lt;NA&gt;      &lt;NA&gt;      (25,50]   (25,50]  \n[106] (50,75]   &lt;NA&gt;      (0,25]    (50,75]   (0,25]    (25,50]   (25,50]  \n[113] (0,25]    (0,25]    &lt;NA&gt;      (25,50]   &lt;NA&gt;      (50,75]   &lt;NA&gt;     \n[120] (75,100]  (100,125] (75,100]  (75,100]  (75,100]  (75,100]  (50,75]  \n[127] (75,100]  (25,50]   (25,50]   (0,25]    (0,25]    (0,25]    (0,25]   \n[134] (25,50]   (0,25]    (25,50]   (0,25]    (0,25]    (25,50]   (0,25]   \n[141] (0,25]    (0,25]    (0,25]    (0,25]    (0,25]    (25,50]   (0,25]   \n[148] (0,25]    (25,50]   &lt;NA&gt;      (0,25]    (0,25]    (0,25]   \nLevels: (0,25] (25,50] (50,75] (75,100] (100,125] (125,150]\n\nairquality$Ozone_cat &lt;- cut(airquality$Ozone, breaks=seq(0,150,by=25))\nsummary(airquality[,c(1,7)])\n\n     Ozone            Ozone_cat \n Min.   :  1.00   (0,25]   :50  \n 1st Qu.: 18.00   (25,50]  :32  \n Median : 31.00   (50,75]  :12  \n Mean   : 41.03   (75,100] :15  \n 3rd Qu.: 62.00   (100,125]: 5  \n Max.   :135.00   (125,150]: 1  \n NA's   :38       NA's     :38  \n\n\n\n\n\n\n\n\nTry it Out\n\n\n\nWhile the “Age” variable is beneficial, Emmit thinks that having a qualitative variable might be more beneficial. Help him add a new column to the dataframe which classifies an individual as early career (&lt; 35 years old), mid-career (35-55 years old), and late career (&gt; 55 years old).\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Data Analysis</span>"
    ]
  },
  {
    "objectID": "Lecture-8-Exploratory-Data-Analysis.html#step-5-initial-summary",
    "href": "Lecture-8-Exploratory-Data-Analysis.html#step-5-initial-summary",
    "title": "8  Exploratory Data Analysis",
    "section": "8.7 Step 5: Initial Summary",
    "text": "8.7 Step 5: Initial Summary\nStep Five: Initial Summary is all about displaying a summary of the dataset to get some insight into how the data is spread out and where the center of each variable is. We will want to look at the results and ask ourselves what information we can gain from it. To procure a summary of a dataset, simply use the summary() function. The output will be a 5-number summary (with the mean included) along with how many missing values are in each variable.\n\nsummary(airquality)\n\n     Ozone           Solar.R           Wind             Temp      \n Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00  \n 1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00  \n Median : 31.00   Median :205.0   Median : 9.700   Median :79.00  \n Mean   : 41.03   Mean   :185.9   Mean   : 9.958   Mean   :77.88  \n 3rd Qu.: 62.00   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00  \n Max.   :135.00   Max.   :334.0   Max.   :20.700   Max.   :97.00  \n NA's   :38       NA's   :7                                       \n     Month            Day           Ozone_cat \n Min.   :5.000   Min.   : 1.0   (0,25]   :50  \n 1st Qu.:6.000   1st Qu.: 8.0   (25,50]  :32  \n Median :7.000   Median :16.0   (50,75]  :12  \n Mean   :6.993   Mean   :15.8   (75,100] :15  \n 3rd Qu.:8.000   3rd Qu.:23.0   (100,125]: 5  \n Max.   :9.000   Max.   :31.0   (125,150]: 1  \n                                NA's     :38",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Data Analysis</span>"
    ]
  },
  {
    "objectID": "Lecture-8-Exploratory-Data-Analysis.html#step-6-data-visualization",
    "href": "Lecture-8-Exploratory-Data-Analysis.html#step-6-data-visualization",
    "title": "8  Exploratory Data Analysis",
    "section": "8.8 Step 6: Data Visualization",
    "text": "8.8 Step 6: Data Visualization\nAnd finally, the last step we want to do is Step Six: Data Visualizations. In this step, we want to visualize the quantitative data with a histogram using the hist() function and visualize the categorical data with barplots using the barplot() function. For categorical data, we will need to use the table() function to summarize the data first. And as we move throughout the course, we will introduce different visualization techniques which will help us understand the data.\n\nhist(airquality$Ozone, freq = FALSE)\nlines(density(airquality$Ozone, na.rm=TRUE))\n\n\n\n\n\n\n\n\n\ntable(airquality$Ozone_cat)\n\n\n   (0,25]   (25,50]   (50,75]  (75,100] (100,125] (125,150] \n       50        32        12        15         5         1 \n\nbarplot(table(airquality$Ozone_cat))\n\n\n\n\n\n\n\n\nExploratory Data Analysis, and in particular these 6 steps, is something we should carry out every time we start working with new datasets. We do not want to jump into analyzing a dataset without knowing what it looks like or if changes need to be made. After a while, these steps will become second nature to us and we will be able to carry them out relatively quickly.\n\n\n\n\n\n\nTry it Out\n\n\n\nHelp Emmit create a few different visualizations to understand the dataset.\n\n\nClick to see the solution\n\nXXXX INSERT VIDEO XXXX\n\n\n\n\n\nCarry out Exploratory Data Analysis on the “beaver2” dataset:\n\nDisplay the structure of the dataset. What are the datatypes present?\nCreate a new factor variable activ_f from the activ column with levels “No” and “Yes”. Confirm the new variable is a factor.\nWhy might converting activ to a factor be useful in data analysis?\nDisplay a summary of the beaver2 dataset including the new factor variable.\nSuppose you mistakenly overwrite the activ variable. How can you reload the original dataset to recover it?\n\nCarry out Exploratory Data Analysis on the “exam_data” dataset in the “MSMU” library:\n\nUse the help() function to explore the documentation for the built-in exam_data dataset. What does this dataset represent?\nUse str() on the exam_data dataset. How many rows and columns are there? Are there any special values or missing values mentioned?\nIdentify how many missing values are in each column\nDisplay the unique values of the writing.score column sorted in increasing order. What does the range look like including and excluding missing values?\nExplain why it might be important to know how many complete observations exist in this dataset. Use a function to find how many complete rows there are.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exploratory Data Analysis</span>"
    ]
  },
  {
    "objectID": "Lecture-16-Line-of-Best-Fit.html",
    "href": "Lecture-16-Line-of-Best-Fit.html",
    "title": "16  Line of Best Fit",
    "section": "",
    "text": "WORK IN PROGRESS",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Line of Best Fit</span>"
    ]
  },
  {
    "objectID": "Lecture-6-Reproducibility-with-RMarkdown.html",
    "href": "Lecture-6-Reproducibility-with-RMarkdown.html",
    "title": "6  RMarkdown",
    "section": "",
    "text": "6.1 Reproducibility using RMarkdown\nSwitching gears, we are at the point of our Data Science journey where we want to focus on our communication skills so that we can inform others of our findings. To do this we will introduce the idea of reproducibility and a new feature called RMarkdown. Other people need to run our code and reproduce our findings. Because, generating results, no matter how noteworthy, are meaningless if they cannot be independently validated.\nWithin R there are a few different ways for us to stay organized. One way is to use scripts in R which will allow us to save our code as a .R file and then run the whole file with one command. Another way is to use text documents to save your code as a .txt file, but we cannot run this with a single command. You need to find out what works for you! I normally create my code in the console and then I copy and paste it into a text file when I want to save it. Others open a script and can run it line by line in there, you will just have to play around and create your style. But, when you do code make sure you create it and run it line by line. Very rarely would we want to create multiple lines of code and then run it and “hope” for the best by running it all at once.\nAnother system that students tend to like (and one we will be using) is RMarkdown. This is a file type in R that will allow us to place our code and comments/explanations side-by-side. We will then be able to “knit” (compile) the file together and it will output a Word document with the output displayed. We will go over this in class together, but to get started you will go to “File -\\(&gt;\\) New File -\\(&gt;\\) RMarkdown”. You may need to install some packages on the first run (just accept them). It will then ask you to pick a Title for the document and an output format (just choose Word or HTML but not PDF).\nRMarkdown relies on YAML (Yet Another Markup Language) so this may be similar to other Markup languages you may have used in other classes. We will just focus on the basics for now, but know that there is a lot of customization and implementations we could do. The Heading will determine the title, output format, and author/date (we will not need to alter anything in here). There are many different ways we can customize the output, but we will keep it fairly simple for now.\nOne aspect that we will be adding/altering is the R “Chunks”. These are between the “` symbols and can be created by hitting the green”C” on the top right of the document. These are where we will place the R code (only the code, not the output!) that we want to run. Outside of the R chunks, we will place out explanations of the code/results so others can understand it. When we are done we will “Knit” it (top middle button) to make it into a Word or HTML document.\n“Knitting” the document will then compile the file. It will run your R code (or other languages if you specify it) and display the output directly following your code. This results in an organized and professional looking document without having to copy and paste our code/results.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>RMarkdown</span>"
    ]
  },
  {
    "objectID": "Lecture-9-More-EDA-and-Loading-in-Data.html",
    "href": "Lecture-9-More-EDA-and-Loading-in-Data.html",
    "title": "9  Loading Data in R & EDA",
    "section": "",
    "text": "9.1 Loading Data into R\nSometimes we are interested in using data that isn’t in R. If this is the case, we will have to load the data into R ourselves using a CSV file. To follow along with this lecture writeup, you should download the dataset called “Data_200_df.csv” on Canvas under the Modules. Now to load data into R there are several different ways we can do it. One way is using the read.csv() function where we pass the file path into the function.\n# My file is saved on my Desktop, yours might be saved under Downloads\nData_200_df &lt;- read.csv(\"Desktop/Data_200_df.csv\")\nAn easier method to load data into R (so we don’t have to memorize the function!) is to go to “File -\\(&gt;\\) Import Dataset -\\(&gt;\\) From Text (base)” and then select the file we want to import. Using this method also makes it easier for us to customize our request like identifying if we have row/column headers or if all of the strings should be factors.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Loading Data in R & EDA</span>"
    ]
  },
  {
    "objectID": "Lecture-9-More-EDA-and-Loading-in-Data.html#converting-character-vectors-to-factors",
    "href": "Lecture-9-More-EDA-and-Loading-in-Data.html#converting-character-vectors-to-factors",
    "title": "9  Loading Data in R & EDA",
    "section": "9.2 Converting character vectors to factors",
    "text": "9.2 Converting character vectors to factors\nNow that we have the data loaded into our R environment, we can start to do some Exploratory Data Analysis (EDA) on it. The first thing we will want to do is look at the structure of the dataset to see what we are dealing with. This can be done using the str() function. In our case here, we do not have any documentation to compare our data or to learn about the dataset.\n\nstr(Data_200_df)\n\n'data.frame':   50 obs. of  6 variables:\n $ names : chr  \"Theresa\" \"Clyde\" \"Katrina\" \"Ricky\" ...\n $ ages  : int  21 20 19 19 19 23 18 21 24 23 ...\n $ state : chr  \"NY\" \"NC\" \"NY\" \"NY\" ...\n $ year  : chr  \"Freshman\" \"Freshman\" \"Sophmore\" \"Sophmore\" ...\n $ majors: chr  \"Psych\" \"Comp-Sci\" \"Math\" \"Psych\" ...\n $ sport : int  0 1 1 0 1 1 0 0 0 0 ...\n\n\nLooking at this, it would probably make sense to turn a couple of these columns into factors instead of having them be character/integer vectors. This can be done using the factor() function and then altering the levels if need be (since sport is given as 0 or 1 we may want to alter the level name to No and Yes). We should only convert a vector to a factor column if there are finite number of categories and there are multiple occurrences of each category. So, we will not need to convert the “names” column since they are all unique and there are virtually infinite number of possibilities.\n\nData_200_df$state_f &lt;- factor(Data_200_df$state)\nData_200_df$year_f &lt;- factor(Data_200_df$year)\nData_200_df$majors_f &lt;- factor(Data_200_df$majors)\n\nData_200_df$sport_f &lt;- as.factor(Data_200_df$sport)\nlevels(Data_200_df$sport_f) &lt;- c(\"No\", \"Yes\")",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Loading Data in R & EDA</span>"
    ]
  },
  {
    "objectID": "Lecture-9-More-EDA-and-Loading-in-Data.html#utilizing-the-table-function",
    "href": "Lecture-9-More-EDA-and-Loading-in-Data.html#utilizing-the-table-function",
    "title": "9  Loading Data in R & EDA",
    "section": "9.3 Utilizing the Table function",
    "text": "9.3 Utilizing the Table function\nTo better understand the dataset, it is helpful to calculate some descriptive statistics and create some visualizations as well. To calculate descriptive statistics for a categorical variable we can use the table() function. This will tell us how many times each category occurs.\n\ntable(Data_200_df$year)\n\n\nFreshman   Junior   Senior Sophmore \n      15       12       10       13 \n\nbarplot(table(Data_200_df$year))\n\n\n\n\n\n\n\n\n\ntable(Data_200_df$majors)\n\n\n    Chem Comp-Sci     Data  History     Math    Psych \n      12        9       10        2       10        7 \n\nbarplot(table(Data_200_df$majors))\n\n\n\n\n\n\n\n\nSo, this shows us the number of students who are Juniors, and the number of students who are Data majors, but can we determine how many Junior Data majors we have? One way we could do this is by using a logical vector:\n\nsum(Data_200_df$year==\"Junior\" & Data_200_df$majors==\"Data\")\n\n[1] 2\n\n\nIf we are interested in other combinations we certainly could carry out the process again and again for all 24 combinations. Another way that will count the number of students who fall into each category is to use the table() function but pass two categorical variables into it. It will count the number of occurrences for each combination of groupings.\n\ntable(Data_200_df$majors, Data_200_df$year)\n\n          \n           Freshman Junior Senior Sophmore\n  Chem            4      3      2        3\n  Comp-Sci        4      3      1        1\n  Data            1      2      2        5\n  History         1      1      0        0\n  Math            3      1      4        2\n  Psych           2      2      1        2",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Loading Data in R & EDA</span>"
    ]
  },
  {
    "objectID": "Lecture-9-More-EDA-and-Loading-in-Data.html#utilizing-the-aggregate-function",
    "href": "Lecture-9-More-EDA-and-Loading-in-Data.html#utilizing-the-aggregate-function",
    "title": "9  Loading Data in R & EDA",
    "section": "9.4 Utilizing the Aggregate function",
    "text": "9.4 Utilizing the Aggregate function\nAnother type of descriptive statistic that we can calculate is the mean on one of the variables (age in our case). While this is helpful, it might also be interesting to see the mean age by major, and to do this we can use a logical vector within our index-selection brackets.\n\nmean(Data_200_df$ages)\n\n[1] 20.7\n\nmean(Data_200_df$ages[Data_200_df$majors==\"Psych\"])\n\n[1] 20.42857\n\nmean(Data_200_df$ages[Data_200_df$majors==\"Chem\"])\n\n[1] 20.91667\n\nmean(Data_200_df$ages[Data_200_df$majors==\"History\"])\n\n[1] 18\n\n\nRunning a line of code for every major is tedious and cumbersome. To do it more efficiently we could use the aggregate() function. In this function, we will pass in the variable we want to calculate, then specify what we want to group by (which needs to be in the list() function and be a categorical variable), and finally specifying the function we want to run. The general setup for this function will be:\naggregate(Quantitative_Variable, by = list(Categorical_Grouping_Variable), math_function)\nAn example of this function can be seen below:\n\naggregate(Data_200_df$ages, by=list(Data_200_df$majors), mean)\n\n   Group.1        x\n1     Chem 20.91667\n2 Comp-Sci 21.44444\n3     Data 19.90000\n4  History 18.00000\n5     Math 21.30000\n6    Psych 20.42857\n\n\nThe way we can read the output from above is that the average age of Chemistry majors is 20.92, the average age of Computer Science majors is 21.44, and so on. We can divide our population up into more groups if we want. For instance, maybe we want to find the average age of people based on their major and whether they play a sport. To do this we will pass in two variables in the by argument.\n\naggregate(Data_200_df$ages, \n          by=list(majors = Data_200_df$majors, \n                  sports = Data_200_df$sport), \n          mean)\n\n     majors sports        x\n1      Chem      0 20.60000\n2  Comp-Sci      0 21.80000\n3      Data      0 20.60000\n4      Math      0 21.20000\n5     Psych      0 21.00000\n6      Chem      1 21.14286\n7  Comp-Sci      1 21.00000\n8      Data      1 19.20000\n9   History      1 18.00000\n10     Math      1 21.40000\n11    Psych      1 19.00000\n\n\nFor this output, we would interpret it similarly. We would say the average age of Chemistry majors who do not play a sport is 20.60, and the average age of Chemistry majors who play a sport is 21.14. We can then do it for all possible combinations of majors and whether they play a sport or not. We can also carry this out using different functions like sd, length, median, and so on.\n\naggregate(Data_200_df$age, by=list(state= Data_200_df$state), sd)\n\n  state        x\n1    MD 2.345208\n2    NC 1.378405\n3    NY 2.101805\n4    PA 2.645751\n5    VA 1.612452\n6    WV 2.438123\n\n\nWithin this section, we have learned two powerful functions which help us summarize categorical and quantitative data. We should think about what data we have present though before we run the code. If we try to run the table function on data that is not categorical (with relatively few categories) or if we try to use the aggregate function and group by quantitative data then the output will not be readable due to the number of possibilities. Therefore, it is important to think about what type of data we are passing into each function and whether the output is particularly useful.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Loading Data in R & EDA</span>"
    ]
  },
  {
    "objectID": "Lecture-10-Probability-Distributions.html",
    "href": "Lecture-10-Probability-Distributions.html",
    "title": "10  Probability Distributions",
    "section": "",
    "text": "10.1 Overview of Probability\nWhen it comes to data, it normally follows some pattern. The trouble is trying to identify what the pattern is. There are a few ways we could do this; one way is to try and guess the pattern using specific examples or we could observe large amounts of data to try and find a pattern. The first method will require us to learn about different probability distributions and their properties while the second method will require simulating datasets and looking at the results.\nTo understand probability distributions, we should probably have a brief review of the topic. Probability is the measure of the likelihood that an event will occur. This likelihood is expressed as a number between 0 and 1, where 0 will indicate impossibility and 1 indicate certainty. The value will always be between 0 and 1 with the sum of probabilities being equal to 1. Some short-hand which you might seen is P(A), which indicates the ``probability of event A occurring”.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Probability Distributions</span>"
    ]
  },
  {
    "objectID": "Lecture-10-Probability-Distributions.html#discrete-probability",
    "href": "Lecture-10-Probability-Distributions.html#discrete-probability",
    "title": "10  Probability Distributions",
    "section": "10.2 Discrete Probability",
    "text": "10.2 Discrete Probability\n\n10.2.1 Bernoulli Distribution\nIf we think about flipping a coin, we might ask what the probability of landing on heads or tails is. We know that there is an equal chance (as long as the coin is fair) of landing on either side, so we will say \\(P(H)=0.5\\) and \\(P(T)=0.5\\). But, if we flip the coin two times we will not always get heads and tails 50% of the time (that is 1 head and 1 tail). To see this phenomenon we can carry out a simulation in R.\n\nsample(c(\"Head\", \"Tail\"), 2, replace=TRUE)\n\n[1] \"Tail\" \"Tail\"\n\nsample(c(\"Head\", \"Tail\"), 2, replace=TRUE)\n\n[1] \"Head\" \"Tail\"\n\nsample(c(\"Head\", \"Tail\"), 2, replace=TRUE)\n\n[1] \"Tail\" \"Head\"\n\n\nWe can take this a step further by flipping 10 coins. We would expect to see roughly 5 Heads and 5 Tails, but we would not expect to always see 5 heads and 5 tails. As we can see from the simulation below, we sometimes get only 3 or 4 Heads and the rest Tails. The more observations we have (that is the more coin flips we do) the closer we should be to the expected proportion (50-50). A simulation below produced heads in 30% of the coin flips, but if we flip 10,000 coins we would find it highly unusual to witness heads only 30% of the time, as we expect the proportion of heads to be much closer to 50%.\n\nsample(c(\"H\", \"T\"), 10, replace=TRUE)\n\n [1] \"H\" \"H\" \"H\" \"T\" \"T\" \"H\" \"T\" \"H\" \"H\" \"T\"\n\nsample(c(\"H\", \"T\"), 10, replace=TRUE)\n\n [1] \"H\" \"H\" \"H\" \"T\" \"H\" \"T\" \"H\" \"H\" \"H\" \"H\"\n\nsample(c(\"H\", \"T\"), 10, replace=TRUE)\n\n [1] \"H\" \"T\" \"H\" \"T\" \"T\" \"T\" \"T\" \"H\" \"H\" \"H\"\n\n\n\nflip &lt;- sample(c(\"H\", \"T\"), 10000, replace=TRUE)\ntable(flip)\n\nflip\n   H    T \n4998 5002 \n\nbarplot(table(flip))\n\n\n\n\n\n\n\n\nWhat would happen though if the coin wasn’t fair and gave us \\(P(H)=0.75\\)? Then we would expect to get Heads roughly 75% of the time and Tails roughly 25% of the time. To do this simulation in R, we could alter the probabilities of each value in the vector using the prob argument.\n\nunfair &lt;- sample(c(\"H\", \"T\"), 10000, prob=c(.75,.25), replace=TRUE)\ntable(unfair)\n\nunfair\n   H    T \n7401 2599 \n\nbarplot(table(unfair))\n\n\n\n\n\n\n\n\nThe examples we have seen will lead us to the idea of the Bernoulli Distribution. For this probability distribution, the results are either Success (1) or Failure (0). The probability of success is usually denoted by \\(p\\) with the probability of failure being \\(q=1-p\\). The probability distribution function can be written as: \\[ P(X=k) = p^k (1-p)^{1-k}\\]\nwhere \\(k=1\\) means success and \\(k=0\\) means failure. Other things to note about this distribution are that the mean will be \\(\\mu=p\\) (note: \\(\\mu\\) represents the population mean and is pronounced “mew”) and the standard deviation will be \\(\\sigma= \\sqrt{p(1-p)}\\). (note: \\(\\sigma\\) represents the population standard deviation is the pronounced “sigma”).\n\n\n10.2.2 Utilizing the Matrix and Apply function\nThe Bernoulli distribution will only concern itself with a single outcome, but what if we are instead interested in flipping a coin 10 times and counting the number of heads that occur? We have already seen that we would expect roughly 5 heads, but it will not always be exact. To model this problem, we could do some simulations in R again. For this problem, I will instead use 1 (to represent Heads) and 0 (to represent Tails) as well as using the matrix() function and apply() function.\nThe matrix() function will allow us to fill in a matrix with values from our sample. We will indicate the number of rows we want in the matrix and it will figure out how many columns are needed to accommodate all of the data we give it. We should be aware though that it will start repeating the data if we do not pass it enough data to complete the rectangular matrix. In the example below, we can see how it will fill in the matrix if we pass it 10 values and indicate we only want 3 rows:\n\nmatrix(1:10, nrow=3)\n\nWarning in matrix(1:10, nrow = 3): data length [10] is not a sub-multiple or\nmultiple of the number of rows [3]\n\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8    1\n[3,]    3    6    9    2\n\n\nThe apply() function will allow us to apply a function on a matrix in R. To use this function, we will need to pass it a matrix and indicate if we want to do the function across the rows (MARGIN=1) or the columns (MARGIN=2). Finally, we do have to pass it a function to carry out (like mean, sum, sd, etc.).\n\nx_mat &lt;- matrix(1:10, nrow=3)\n\nWarning in matrix(1:10, nrow = 3): data length [10] is not a sub-multiple or\nmultiple of the number of rows [3]\n\napply(x_mat, MARGIN=1, sum) # Calculating the sum for each row\n\n[1] 22 16 20\n\napply(x_mat, MARGIN=2, sum) # Calculating the sum for each column\n\n[1]  6 15 24 13\n\n\nI encourage you to play around with the matrix() and apply() functions to get a sense of how they work since we will be using them to do simulations in R quite a bit.\n\n\n10.2.3 Binomial Distribution\nIn the simulation below, we are flipping 10 coins (columns), writing down the results, and repeating this process a total of 12 times (rows). We then count the number of heads that occur in each row. Visualizing it as a table allows us to see the number of times each result occurred. We can see that we occasionally got 7 Heads, but the majority of the time we had close to 5 Heads.\n\nflips &lt;- matrix(sample(c(1, 0), 10*12, replace=TRUE), nrow=12)\nflips\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]    0    1    1    1    1    0    1    1    0     0\n [2,]    1    1    0    1    1    1    0    1    0     1\n [3,]    1    1    1    1    1    1    0    1    0     0\n [4,]    1    1    0    1    0    1    1    1    0     0\n [5,]    1    1    1    1    0    1    0    0    0     0\n [6,]    1    1    1    0    0    1    1    1    0     0\n [7,]    0    1    0    1    1    0    0    1    0     1\n [8,]    1    0    1    0    0    0    0    1    0     1\n [9,]    0    1    1    1    1    1    1    0    0     0\n[10,]    1    0    0    1    1    1    0    0    1     0\n[11,]    0    1    1    0    0    1    0    0    1     0\n[12,]    1    0    1    0    0    1    1    0    0     0\n\nnheads &lt;- apply(flips, MARGIN=1, FUN=sum)\nnheads\n\n [1] 6 7 7 6 5 6 5 4 6 5 4 4\n\ntable(nheads) # Results of flipping 10 coins 12 times\n\nnheads\n4 5 6 7 \n3 3 4 2 \n\nbarplot(table(factor(nheads, levels=0:10)))\n\n\n\n\n\n\n\n\nInstead of just doing it 12 times, what if we did it 100 times or even 10,000 times? How might our counts and barplot look?\n\nnumber_of_times &lt;- 100\nflips &lt;- matrix(sample(c(1, 0), 10*number_of_times, replace=TRUE), nrow=number_of_times)\nnheads &lt;- apply(flips, MARGIN=1, FUN=sum)\ntable(nheads) # Results of flipping 10 coins 100 times\n\nnheads\n 1  2  3  4  5  6  7  8  9 \n 1  8 12 16 28 19 10  4  2 \n\nbarplot(table(factor(nheads, levels=0:10)))\n\n\n\n\n\n\n\n\n\nnumber_of_times &lt;- 10000\nflips &lt;- matrix(sample(c(1, 0), 10*number_of_times, replace=TRUE), nrow=number_of_times)\nnheads &lt;- apply(flips, MARGIN=1, FUN=sum)\ntable(nheads) # Results of flipping 10 coins 100 times\n\nnheads\n   0    1    2    3    4    5    6    7    8    9   10 \n  15   90  404 1186 2068 2458 2036 1184  440  106   13 \n\nbarplot(table(factor(nheads, levels=0:10)))\n\n\n\n\n\n\n\n\nIn the simulations, the individual flips are represented by the Bernoulli distribution (success or failure). The sequence of flipping to coin 10 times is known as a Bernoulli trial. The Binomial Distribution represents the number of successes in \\(n\\) Bernoulli trials. Notice that when \\(n=1\\) we have a Bernoulli Distribution. The probability distribution function can be written as:\n\\[ \\text{P(X=k)}={n\\choose k}p^k(1-p)^{n-k}=\\frac{n!}{(n-k)!k!}p^kq^{n-k}\\]\nwhere \\(n\\) is the number of trials, \\(k\\) is the number of successes, and \\(p\\) is the probability of success. Other things to note about this distribution are that the mean will be \\(\\mu=np\\) and the standard deviation will be \\(\\sigma=\\sqrt{np(1-p)}\\).\n\n\n10.2.4 Theoretical vs Empirical Probability\nNow that we know a few different probability distribution functions, we should probably discuss the 2 main ways we can calculate probabilities. The first way is to calculate it theoretically if we know the underlying distribution. To do this, we would need to evaluate the probability distribution function at the desired value. If we do not, then we can calculate it empirically if we have a large number of observations available to us. To do this, we will simply see the proportion of values that meet the desired criteria.\nTake the following example: If we were to flip a coin 10 times, what is the probability that we would end up with exactly 4 heads? This is a Binomial Distribution with \\(n=10\\) and \\(p=0.5\\), which is can be written as Bin(10,0.5), so:\n\\[ \\text{P(X=4)}={10\\choose 4}0.5^4(1-0.5)^{10-4}\\approx 0.2050781 \\]\n\nchoose(10,4)*0.5^4*(1-0.5)^(10-4)\n\n[1] 0.2050781\n\nfactorial(10)/(factorial(6)*factorial(4))*0.5^4*0.5^6\n\n[1] 0.2050781\n\n\nThis is called the Theoretical Probability since we know what the distribution is for our question. If we did not know what the probability distribution was then we can always simulate it similarly to what we did above. For this, we simulated 10,000 10-flip trials and counted the number of heads in each trial:\n\ntable(nheads)\n\nnheads\n   0    1    2    3    4    5    6    7    8    9   10 \n  15   90  404 1186 2068 2458 2036 1184  440  106   13 \n\n2068/10000\n\n[1] 0.2068\n\n\nThis is called the Empirical Probability since we have a large number of observations. We can see that the proportion of 4 heads is roughly 0.2068 when we ran it 10,000 times. Notice this is very close to our theoretical probability! We can do something similar if our coin is not fair. For instance, if we flip 10 coins 10,000 times when the probability of heads was 0.75 then we might get results that look like this:\n\nn &lt;- 10000 # number of times flipping the 10 coins\nflips &lt;- matrix(sample(c(1, 0), 10*n, replace=TRUE, prob=c(0.75, 0.25)), nrow=n)\nnheads &lt;- apply(flips, MARGIN=1, FUN=sum)\ntable(nheads)\n\nnheads\n   2    3    4    5    6    7    8    9   10 \n   1   24  182  549 1445 2476 2846 1919  558 \n\n\nWe can then calculate the probability of getting exactly 4 heads both theoretically and empirically. We will notice that the empirical probability gives us a good estimation as long as we carry out a large number of simulations.\n\nchoose(10,4)*0.75^4*(1-0.75)^6\n\n[1] 0.016222\n\n182/10000\n\n[1] 0.0182\n\n\n\n\n10.2.5 Uniform Discrete Distribution\nInstead of flipping a coin, what if we instead rolled a standard die? We might ask ourselves: what the probability is of getting a 1? What about a 2 or a 3? It is fairly easy to calculate these probabilities theoretically since there are 6 sides on a die with each being equally likely. This gives us a probability of \\(\\frac{1}{6}\\) for each event. We can also run a simulation to determine the probability:\n\nsample(1:6, 10, replace=TRUE)\n\n [1] 3 3 6 4 6 4 3 1 4 6\n\nsample(1:6, 10, replace=TRUE)\n\n [1] 5 3 1 4 5 1 3 5 5 6\n\n\nWe can then count the number of times each event occurs and visualize it with a barplot.\n\nx &lt;- sample(1:6, 10, replace=TRUE)\nx &lt;- factor(x, levels=1:6)\ntable(x)\n\nx\n1 2 3 4 5 6 \n2 5 1 1 0 1 \n\nbarplot(table(x))\n\n\n\n\n\n\n\n\nNotice how in the visualization above each outcome is not equally represented. This is because when our sample size is small it will not necessarily look like what we expect, but as the sample size increases it looks closer and closer to the theoretical probability. To see this we can visualize rolling 50 dice or even 10,000 dice:\n\nx &lt;- sample(1:6, 50, replace=TRUE)\ntable(x)\n\nx\n 1  2  3  4  5  6 \n 7 15 10  6  4  8 \n\nbarplot(table(x))\n\n\n\n\n\n\n\n\n\nx &lt;- sample(1:6, 10000, replace=TRUE)\ntable(x)\n\nx\n   1    2    3    4    5    6 \n1628 1668 1685 1656 1629 1734 \n\nbarplot(table(x))\n\n\n\n\n\n\n\n\nIf all outcomes have an equal chance of occurring then the probability is identical (uniform) for all possible outcomes. It can be modeled using a Uniform Discrete Distribution. The probability distribution can be described as:\n\\[ P(X=k)=\\frac{1}{n}\\]\nwhere \\(n\\) is the number of possible outcomes. For this distribution, the mean will be \\(\\mu=\\frac{a+b}{2}\\) (where \\(a\\) and \\(b\\) are the “end-points”) and the standard deviation will be \\(\\sigma=\\sqrt{\\frac{n^2-1}{12}}\\). We will only really have to deal with these if our outcomes are quantitative and sequential (or at least evenly separated).\n\n\n10.2.6 Poisson Distribution\nThe last discrete probability distribution we want to discuss is the Poisson Distribution. This distribution will give us the probability of a given number of events occurring in a fixed time interval. This will only apply if the events occur at a constant rate \\(\\lambda\\) (pronounced “lambda”) and the events are independent of each other (meaning one occurrence does not affect another occurrence). The probability distribution can be described as: \\[ \\text{P(X=k)}=\\frac{\\lambda^ke^{-\\lambda}}{k!}\\]\nwith \\(e\\) being the mathematical constant \\(2.71828\\dots\\). Some properties of this distribution are that the mean is \\(\\mu=\\lambda\\) and the standard deviation is \\(\\sigma = \\sqrt{\\lambda}\\).\nTo create simulations for this distribution in R, we will use the rpois() function which generate random values from the Poisson distribution. Similar functions exist for other distributions as well (such as rbinom() for random values from a binomial distribution). Additional functions will allow us to calculate theoretical probabilities in R using \\(p\\) instead of \\(r\\) at the front of the function. We will discuss these in more detail during future lectures.\nLet’s consider the following example: A considerable amount of 18-Wheelers drive down Emmitsburg’s Main Street each day. If they come through at a rate of 2 per 15 minutes, what would we expect to see the distribution look like? What happens if the rate changes to 5 per 15 minutes?\n\nx &lt;- rpois(10000,lambda=2) # Random values assuming 2 per 15-minutes\ntable(x)\n\nx\n   0    1    2    3    4    5    6    7    8    9 \n1336 2743 2676 1778  948  364  120   24    8    3 \n\nbarplot(table(x))\n\n\n\n\n\n\n\n\n\nx &lt;- rpois(10000,lambda=5) # Random values assuming 5 per 15-minutes\ntable(x)\n\nx\n   0    1    2    3    4    5    6    7    8    9   10   11   12   13   14   15 \n  64  356  864 1417 1745 1764 1457 1033  632  366  153   94   35   14    4    1 \n  16 \n   1 \n\nbarplot(table(x))\n\n\n\n\n\n\n\n\nAltering the lambda will affect the distribution’s shape. Below shows a few different lambdas along with how the distribution will look\n\n\n\n\n\nGoing back to the example, we can calculate the probability the 4 trucks drive through town if the rate is 5 per 15 minutes. This can be done both theoretically (the top example) and empirically (the bottom example):\n\n(5^4 * exp(-5))/factorial(4)\n\n[1] 0.1754674\n\n1745/10000\n\n[1] 0.1745\n\n\nWe could also find the Probability of seeing less than or equal to 4 18-Wheelers:\n\nsum(x&lt;=4)/10000\n\n[1] 0.4446",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Probability Distributions</span>"
    ]
  },
  {
    "objectID": "Lecture-10-Probability-Distributions.html#population-sample-the-law-of-large-numbers",
    "href": "Lecture-10-Probability-Distributions.html#population-sample-the-law-of-large-numbers",
    "title": "10  Probability Distributions",
    "section": "10.3 Population, Sample, & the Law of Large Numbers",
    "text": "10.3 Population, Sample, & the Law of Large Numbers\nSince we are coming to the end of the lecture on discrete probability distributions, we should probably cover a few definitions that will pop up throughout the rest of the course. The first is the difference between a population and a sample. A population is the entire collection of possible values for a measured observation, while a sample is just the subset of the population that we collect. For instance, if you are interested in the number of siblings all college students have then your population would be all college students while your sample is just the students you get data on.\nThe next definition we should discuss is a random variable. A random variable is the value of an observation determined by a chance event. For instance, rolling a die or flipping a coin would be a random variable. A Frequency Distribution is the frequency of a random variable occurring at all observed values. This will help us calculate empirical probabilities and is an approximation for the population distribution.\nLastly, we have seen throughout this lecture that as we increase the sample size, the visualization looks closer and closer to what we would expect. This is due to the Law of Large Numbers, which states that as our sample gets larger and larger, the relative frequencies will converge to the probability from the population distribution.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Probability Distributions</span>"
    ]
  },
  {
    "objectID": "Lecture-10-Probability-Distributions.html#continuous-probability",
    "href": "Lecture-10-Probability-Distributions.html#continuous-probability",
    "title": "10  Probability Distributions",
    "section": "10.4 Continuous Probability",
    "text": "10.4 Continuous Probability\nLast in this chapter we discussed some Discrete Distributions and were able to calculate the probability that a single event occurred. We can do a similar idea with continuous data except that instead of calculating \\(P(X=a)\\), we will be calculating the probability of falling within a range of values such as \\(P(X&lt;a)\\) or \\(P(a\\leq X \\leq b)\\). This should hopefully make sense as continuous data can take on any value in a given interval, so the probability that our backpack weighs exactly 6.4939 pounds is 0 since this is only 1 value with an infinite amount of possibilities if the scale can be infinitely precise. For the students who have taken calculus before, we (should) know that the integral at a single point, that is \\(\\int_a^a f(x)\\ dx\\), is 0.\n\n10.4.1 Uniform Continuous Distribution\nThe first distribution we will discuss is the Uniform Continuous Distribution. Similar to the Uniform Discrete Distribution, all possibilities within the interval \\([a,b]\\) have the same chance of being selected. The visualization of this distribution is essentially “flat” across the specified interval. The Uniform Continuous distribution can be described by the probability distribution \\(f(x)=\\frac{1}{b-a}\\) when \\(a\\leq x \\leq b\\) and \\(f(x)=0\\) otherwise. The mean will be \\(\\mu=\\frac{b+a}{2}\\) and the standard deviation will be \\(\\sigma = \\sqrt{\\frac{(b-a)^2}{12}}\\)\\\nUniform Distributions occur when all of the ranges of outputs are equally likely. People’s heights typically are not uniformly distributed (as most people are around 68 inches tall, with a few really short people and a few tall people). But, if we look at the decimal values of the height (for a person 68.283 inches tall if we just use the .283 portion) then that would be uniformly distributed. This idea of a continuous Uniform distribution is also seen in Random Number Generators, which are vital in simulations and computer applications!\nThe code to simulate a uniform continuous distribution in R is fairly straightforward. We will use the runif() function which requires us to specify the number of random uniform numbers. We can also specify the minimum and maximum values for the digits. If we do not specify this then it will return values between 0 and 1. To view discrete data we used a barplot, but if we want to view the continuous data then we should utilize a histogram using the hist() function.\n\nrunif(5)\n\n[1] 0.3039341 0.3271780 0.9936374 0.7228282 0.8854631\n\nrunif(5, min=13, max=15)\n\n[1] 13.20895 14.21335 13.97186 13.69464 14.81628\n\nuniform_data &lt;- runif(100, min=0, max=1)\nhist(uniform_data, col=\"lightblue\", main=\"Uniform Distribution\", \n     breaks=20, freq = FALSE)\n\n\n\n\n\n\n\n\nNow we might not have gotten a very Uniform looking visualization with the code above, and that is because our sample of size 100 is relatively small. The Law of Large Numbers tells us that as our sample grows larger and larger, our distribution will get closer and closer to the expected population distribution. So now try running the same code but change the sample size from 100 to 100,000 and see how it looks more uniform.\n\nuniform_data &lt;- runif(100000, min=0, max=1)\nhist(uniform_data, col=\"lightblue\", main=\"Uniform Distribution\", \n     breaks=20, freq = FALSE)\n\n\n\n\n\n\n\n\n\n\n10.4.2 Gamma Distribution\nThe Gamma Distribution is another continuous distribution that has important aspects in the world of Data Science. This distribution has values that are always positive and right-skewed (meaning we have an outlier on the right side, making the “tail” longer). This distribution is particularly useful in describing the time until the \\(n^{\\text{th}}\\) Poisson event. We will not worry about ``math” of the function, but we will note that the curve is defined by shape \\(k\\) and scale \\(\\theta\\). The mean will end up being \\(\\mu=k\\theta\\) and the standard deviation will be \\(\\sigma=\\sqrt{k\\theta^2}\\)\nWe should note that this distribution can be used for any data which we anticipate will be skewed, and does not have to deal with just the time until the \\(n^{\\text{th}}\\) Poisson event. To simulate random values for a gamma distribution we will use the rgamma() function where we can specify the number of values we want along with the shape, and either the scale or rate (sometimes we might also mention rate which is 1/scale). The visualization below shows what the distribution may look like. A density line has been drawn over the top of the histogram to help visualize the distribution.\n\ngamma_data &lt;- rgamma(50, shape=2.5, scale=20000)\nhist(gamma_data, col=\"lightblue\", main=\"Salary of Population\", \n     freq=FALSE)\nlines(density(gamma_data), col=\"red\", lwd=2)\n\n\n\n\n\n\n\n\nEvery time you run the code above you may get vastly different-looking graphs, which is due to the small sample size of our data. The Law of Large Numbers (wow…second time it has been mentioned, it must be important…) tells us that we need a large sample for it to look like a “smooth” distribution. If we have a relatively small sample then we cannot guarantee it will look “nice”. The visualization below shows how the shape and scale affect the look of the distribution:\n\n\n\n\n\n\n\n\n\n\n\n10.4.3 Exponential Distribution\nThe Exponential Distribution is going to be similar to the Gamma Distribution with one slight caveat, it is the time between Poisson events and not the time until the \\(n^{\\text{th}}\\) event. This is often referred to as a memory-less distribution as we start over each time we see an observation and count the time til the next one. So, the Exponential Distribution is a special case of the Gamma distribution when the shape is 1 and the scale is \\(\\frac{1}{\\lambda}\\). The mean and standard deviation for this distribution will be \\(\\mu=\\sigma=\\frac{1}{\\lambda}\\).\nThis is useful when we are interested in determining the arrival time between events. If we go back to our example of 18-wheelers driving down Main Street at a rate of 4 per 15 minutes, we can determine the time between the 18-wheelers coming through the city.\n\nexp_data &lt;- rexp(50, rate=4)\nhist(exp_data, col=\"lightblue\", main=\"Exponential Distribution\", \n     xlab=\"Time Between 18-Wheelers\", breaks=20, freq=FALSE)\nlines(density(exp_data), col=\"red\")\n\n\n\n\n\n\n\n\nOnce again, this probably does not look very nice or smooth as we have relatively few pieces of data visualized. I encourage you to try the code above again but this time change the number of observations in the sample from 50 to 5,000 and see how different it looks. We could also rewrite the rate to alter the units. Currently, it is 4 per 15 minutes, but we could also have it as \\(4\\times4=16\\) for 16 every hour or even \\(4/15\\) for the amount per minute. This would change the units on the x-axis to whatever units the rate is in.\n\nexp_data &lt;- rexp(1000, rate=4/15)\nhist(exp_data, col=\"lightblue\", main=\"Exponential Distribution\", \n     xlab=\"Time Between 18-Wheelers\", breaks=20, freq=FALSE)\nlines(density(exp_data), col=\"red\")\n\n\n\n\n\n\n\n\n\n\n10.4.4 Normal Distribution\nWe will see that many characteristics in nature follow what we call the Normal Distribution. This is a uni-modal (one hump) symmetric distribution centered around the mean with the shape dependent on the standard deviation. You have probably heard people refer to the “bell” curve before since it tends to resemble the shape of a bell. Characteristics such as heights, grades, stock market returns, blood pressure, and many more things follow this distribution. It can be described by its mean \\(\\mu\\) and the standard deviation \\(\\sigma\\), both of which are arguments that we can decide.\nThis is one of the most important distributions in statistics, as we will be revisiting this distribution continually throughout the rest of the semester. Later on, we will see why it is so important and how it relates to arguably one of the Top 3 Most Influential Theorems (the Central Limit Theorem). We can see the distribution at work if we want to look at the average height of students. We will assume the average height is 68 inches while the standard deviation is 3 inches.\n\nnormal_data &lt;- rnorm(100, mean=68, sd=3)\nhist(normal_data, col=\"lightblue\", main=\"Height of Students\", \n     breaks=20, freq=FALSE)\nlines(density(normal_data), col=\"red\", lwd=2)\n\n\n\n\n\n\n\n\nOnce again, if we increase the sample size, it will look more and more smooth due to the Law of Large Numbers (another very important and influential theorem). There are a lot of neat properties that come from the Normal Distribution, one of which is called the 68-95-99.7 Rule. This states that roughly 68% of our data falls within 1 standard deviation of the mean, 95% of our data falls within 2 standard deviations of the mean, and 99.7% of our data falls within 3 standard deviations of the mean.\nGiven the normally distributed data that we created above, we could test this idea and see if the 68-95-99.7 Rule does hold up. The following code is an example of how we may see it. Note that you may get different results due to the fact you will be generating a different random sample than I have. I will increase the sample size to 1000 to get more accurate results.\n\nnormal_data &lt;- rnorm(1000, mean=68, sd=3)\nmean(normal_data)\n\n[1] 68.0472\n\nsd(normal_data)\n\n[1] 3.007\n\nhist(normal_data, col=\"lightblue\", main=\"Height of Students\", \n     breaks=20, freq=FALSE)\nlines(density(normal_data), col=\"red\")\n\n\n\n\n\n\n\n\n\nsum(normal_data &gt; mean(normal_data) - sd(normal_data) & \n      normal_data &lt; mean(normal_data) + sd(normal_data))/1000\n\n[1] 0.706\n\nsum(normal_data &gt; mean(normal_data) - 2*sd(normal_data) & \n      normal_data &lt; mean(normal_data) + 2*sd(normal_data))/1000\n\n[1] 0.947\n\n\nSo with this, we can see that the 68-95-99.7 rule is pretty accurate in telling us what percentage of the data is within so many standard deviations of the mean. You should get similar, but slightly different results. The more data in your sample the closer you will be to the true proportion.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Probability Distributions</span>"
    ]
  },
  {
    "objectID": "index.html#note",
    "href": "index.html#note",
    "title": "Introduction to Data Science with R",
    "section": "Note:",
    "text": "Note:\nThis textbook was written by Dr. Jon McCurdy for Mount St. Mary’s University’s Introduction to Data Science course. Special Thanks to student Luke Papayoanou for his input along with developing the MSMU package in R to go along with this book.",
    "crumbs": [
      "Welcome"
    ]
  }
]